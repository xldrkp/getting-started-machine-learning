[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning mit Python",
    "section": "",
    "text": "This is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "introduction/index.html",
    "href": "introduction/index.html",
    "title": "Einführung",
    "section": "",
    "text": "Et nostrud eiusmod incididunt ex consequat do amet. Velit ad mollit do voluptate. Proident velit dolor est non Lorem quis excepteur adipisicing cupidatat eu et consectetur irure. Adipisicing proident enim aliqua excepteur sunt ex aliqua cillum laborum qui. Labore irure id velit Lorem aute.\nDo labore quis anim dolore voluptate incididunt est reprehenderit nisi culpa ad nostrud. Ad dolor minim dolor ut magna ullamco pariatur fugiat non ut deserunt in nostrud. Elit tempor aliqua minim fugiat sit cupidatat enim sunt aliquip.\nUt laboris deserunt reprehenderit deserunt dolor eiusmod id nulla commodo consequat eu aliqua adipisicing deserunt. Exercitation pariatur dolor do irure est veniam quis dolore officia minim occaecat excepteur sit. Dolor Lorem mollit culpa ut commodo ullamco qui ex sit in aliquip. Laborum ipsum fugiat aliqua et amet."
  },
  {
    "objectID": "introduction/theory.html",
    "href": "introduction/theory.html",
    "title": "1  Statistische Grundlagen",
    "section": "",
    "text": "Die Grundlagen verschiedener statistischer Funktionen und Vorgehensweisen zeige ich entlang der sehr guten Einführung zu Machine Learning auf der Seite der W3School.\nDort stehen die folgenden Konzepte im Mittelpunkt:\nIn diesem Grundlagenskript arbeiten wir zunächst auf das Thema Regression hin, um anschließend noch Konzepte der Klassifizierung kennenzulernen."
  },
  {
    "objectID": "introduction/theory.html#decision-tree",
    "href": "introduction/theory.html#decision-tree",
    "title": "1  Statistische Grundlagen",
    "section": "1.1 Decision tree",
    "text": "1.1 Decision tree\n\nhttps://www.askpython.com/python/machine-learning-introduction\n\nProident tempor non exercitation qui. Qui magna commodo nostrud quis. Id nulla ex laboris elit ullamco ut sunt et cillum ut deserunt. Laboris anim veniam elit aliquip. Dolore anim voluptate eiusmod enim proident ea labore non id ex incididunt tempor dolor sit. Occaecat esse tempor proident elit laboris consequat cupidatat."
  },
  {
    "objectID": "introduction/theory.html#literatur-zur-einführung",
    "href": "introduction/theory.html#literatur-zur-einführung",
    "title": "1  Statistische Grundlagen",
    "section": "1.2 Literatur zur Einführung",
    "text": "1.2 Literatur zur Einführung\n\nKirste und Schürholz (2019)\nStubbe, Wessels, und Zinke (2019)\n\n\n\n\n\nKirste, Moritz, und Markus Schürholz. 2019. „Einleitung: Entwicklungswege zur KI“. In Künstliche Intelligenz, herausgegeben von Volker Wittpahl, 21–35. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-58042-4_1.\n\n\nStubbe, Julian, Jan Wessels, und Guido Zinke. 2019. „Neue Intelligenz, neue Ethik?“ In Künstliche Intelligenz, herausgegeben von Volker Wittpahl, 239–54. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-58042-4_15."
  },
  {
    "objectID": "introduction/jupyter-usage.html",
    "href": "introduction/jupyter-usage.html",
    "title": "3  Einführung in JupyterLab",
    "section": "",
    "text": "Tastenbefehle\nMenüs\nHilfe"
  },
  {
    "objectID": "introduction/find-data.html",
    "href": "introduction/find-data.html",
    "title": "4  Daten finden",
    "section": "",
    "text": "https://hub.packtpub.com/best-machine-learning-datasets-for-beginners/"
  },
  {
    "objectID": "introduction/pretrained-models.html",
    "href": "introduction/pretrained-models.html",
    "title": "5  Vortrainierte Modelle",
    "section": "",
    "text": "https://www.tensorflow.org/js/models\nhttps://firebase.google.com/docs/ml-kit\nhttps://tfhub.dev/"
  },
  {
    "objectID": "preparation/numpy.html",
    "href": "preparation/numpy.html",
    "title": "6  numpy",
    "section": "",
    "text": "Multidimensionale Arrays und Matrizen, wissenschaftliche Berechnungen"
  },
  {
    "objectID": "preparation/numpy.html#einfache-statistische-funktionen",
    "href": "preparation/numpy.html#einfache-statistische-funktionen",
    "title": "6  numpy",
    "section": "6.1 Einfache statistische Funktionen",
    "text": "6.1 Einfache statistische Funktionen\nhttps://www.w3schools.com/python/python_ml_mean_median_mode.asp\n\n### Mean\n\n\n#!pip install numpy\n\n\nspeed = [99,86,87,88,111,86,103,87,94,78,77,85,86]\n\n\n6.1.1 Mean (Mittelwert)\n\nimport numpy as np\n\n\nx = np.median(speed)\nx\n\n87.0"
  },
  {
    "objectID": "preparation/numpy.html#übungen-zum-auswählen-von-daten-aus-einer-tabelle",
    "href": "preparation/numpy.html#übungen-zum-auswählen-von-daten-aus-einer-tabelle",
    "title": "6  numpy",
    "section": "6.2 Übungen zum Auswählen von Daten aus einer Tabelle",
    "text": "6.2 Übungen zum Auswählen von Daten aus einer Tabelle\nHier geht es vornehmlich um die Methode iloc in numpy und pandas.\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html?highlight=iloc#pandas.DataFrame.iloc"
  },
  {
    "objectID": "preparation/matplotlib.html",
    "href": "preparation/matplotlib.html",
    "title": "7  matplotlib",
    "section": "",
    "text": "matplotlib ist ein Standard, wenn es um die Visualisierung von Daten mit Python geht. In diesem Abschnitt Lernen Sie die Grundlagen kennen, wobei Sie sich am offiziellen Tutorial der Bibliothek orientieren."
  },
  {
    "objectID": "preparation/matplotlib.html#ein-erstes-beispiel",
    "href": "preparation/matplotlib.html#ein-erstes-beispiel",
    "title": "7  matplotlib",
    "section": "7.1 Ein erstes Beispiel",
    "text": "7.1 Ein erstes Beispiel\n\nimport matplotlib.pyplot as plt\nplt.plot([0, 2, 3, 4])\nplt.ylabel('some numbers')\nplt.show()"
  },
  {
    "objectID": "preparation/matplotlib.html#formatieren-der-visualisierung",
    "href": "preparation/matplotlib.html#formatieren-der-visualisierung",
    "title": "7  matplotlib",
    "section": "7.2 Formatieren der Visualisierung",
    "text": "7.2 Formatieren der Visualisierung\n\nplt.plot([1, 2, 3, 4], [1, 4, 9, 16], 'ro')\nplt.axis([0, 6, 0, 20])\nplt.show()"
  },
  {
    "objectID": "preparation/matplotlib.html#ein-beispiel-mit-numpy",
    "href": "preparation/matplotlib.html#ein-beispiel-mit-numpy",
    "title": "7  matplotlib",
    "section": "7.3 Ein Beispiel mit numpy",
    "text": "7.3 Ein Beispiel mit numpy\n\nimport numpy as np\n\n# evenly sampled time at 200ms intervals\nt = np.arange(0., 5., 0.2)\n\n# red dashes, blue squares and green triangles\nplt.plot(t, t, 'r--', t, t**2, 'bs', t, t**3, 'g^')\nplt.show()"
  },
  {
    "objectID": "preparation/matplotlib.html#aufgaben",
    "href": "preparation/matplotlib.html#aufgaben",
    "title": "7  matplotlib",
    "section": "7.4 Aufgaben",
    "text": "7.4 Aufgaben\n\n\n\n\n\n\nExperimentieren mit matplotlib\n\n\n\n\nLaden Sie das Tutorial als Notebook vom Ende der Tutorialseite herunter.\nBringen Sie es in Ihrem JupyterLab zum Laufen.\nExperimentieren Sie mit den Beispielen, wobei Sie die offzielle Dokumentation benutzen."
  },
  {
    "objectID": "preparation/pandas.html",
    "href": "preparation/pandas.html",
    "title": "8  pandas",
    "section": "",
    "text": "Datenbereinigung und -vorbereitung"
  },
  {
    "objectID": "preparation/pandas.html#normalisierung-vs.-standardisierung",
    "href": "preparation/pandas.html#normalisierung-vs.-standardisierung",
    "title": "8  pandas",
    "section": "8.1 Normalisierung vs. Standardisierung",
    "text": "8.1 Normalisierung vs. Standardisierung\nhttps://www.statology.org/standardization-vs-normalization/"
  },
  {
    "objectID": "machine-learning/index.html",
    "href": "machine-learning/index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Velit in voluptate irure consequat anim velit voluptate mollit duis aute velit. Proident ad id quis minim proident mollit eu elit reprehenderit dolore fugiat. Incididunt adipisicing pariatur deserunt ullamco elit qui nostrud qui aute. Exercitation amet est labore minim ad Lorem anim magna aute consequat aliquip adipisicing aliquip commodo. Aute quis laboris culpa nulla culpa cillum cillum pariatur fugiat consectetur sint velit."
  },
  {
    "objectID": "machine-learning/preprocessing.html",
    "href": "machine-learning/preprocessing.html",
    "title": "9  Daten vorbereiten (data preprocessing)",
    "section": "",
    "text": "#!pip install numpy\n#!pip install pandas\n#!pip install matplotlib"
  },
  {
    "objectID": "machine-learning/preprocessing.html#bibliotheken-importieren",
    "href": "machine-learning/preprocessing.html#bibliotheken-importieren",
    "title": "9  Daten vorbereiten (data preprocessing)",
    "section": "9.2 Bibliotheken importieren",
    "text": "9.2 Bibliotheken importieren\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "machine-learning/preprocessing.html#daten-importieren",
    "href": "machine-learning/preprocessing.html#daten-importieren",
    "title": "9  Daten vorbereiten (data preprocessing)",
    "section": "9.3 Daten importieren",
    "text": "9.3 Daten importieren\nDie Daten, die in diesem Beispiel als CSV-Datei vorliegen, wird mithilfe von pandas importiert.\n\ndataset = pd.read_csv(\"data/dataset.csv\")\n\nDas geladene Datenset kann hier im Notebook angezeigt werden.\n\ndataset\n\n\n\n\n\n  \n    \n      \n      Land\n      Alter\n      Gehalt\n      gekauft\n    \n  \n  \n    \n      0\n      Frankreich\n      44.0\n      72000.0\n      Nein\n    \n    \n      1\n      Griechenland\n      27.0\n      48000.0\n      Ja\n    \n    \n      2\n      Deutschland\n      30.0\n      54000.0\n      Nein\n    \n    \n      3\n      Griechenland\n      38.0\n      61000.0\n      Nein\n    \n    \n      4\n      Deutschland\n      40.0\n      NaN\n      Ja\n    \n    \n      5\n      Frankreich\n      35.0\n      58000.0\n      Ja\n    \n    \n      6\n      Griechenland\n      NaN\n      52000.0\n      Nein\n    \n    \n      7\n      Frankreich\n      48.0\n      79000.0\n      Ja\n    \n    \n      8\n      Deutschland\n      50.0\n      83000.0\n      Nein\n    \n    \n      9\n      Frankreich\n      37.0\n      67000.0\n      Ja\n    \n  \n\n\n\n\nFür die folgenden Operationen auf den Daten muss das Datenset in zwei Bereiche eingeteilt werden. Dabei sind sind die folgenden Gedanken leitend:\nDas zu entwickelnde Modell soll voraussagen können, ob ein Klient Kaufabsichten hat oder nicht. Dafür werden die Features Land, Alter und Gehalt zugrundegelegt. Diese Features sind die unabhängigen Variablen. Die abhängige Variable wiederum ist in der letzten Spalte gekauft zu finden. Sie hängt von den Werten der ersten drei Spalten ab.\nEs gilt also, ein Modell mit den Features der ersten drei Spalten zu trainieren, um eine Voraussage (prediction) für die Kaufabsicht treffen zu können.\nDie folgenden Anweisungen sind sehr allgemein formuliert, damit sie für weitere Aufgaben wiederverwendbar sind. Voraussetzung ist, dass die ersten Spalten eines Datensets die unabhängigen Variablen enthalten, während die abhängige Variable in der letzten Spalte steht."
  },
  {
    "objectID": "machine-learning/preprocessing.html#featurematrix-auswählen",
    "href": "machine-learning/preprocessing.html#featurematrix-auswählen",
    "title": "9  Daten vorbereiten (data preprocessing)",
    "section": "9.4 Featurematrix auswählen",
    "text": "9.4 Featurematrix auswählen\nZunächst werden die Features in einer Variable zusammengefasst, die einer Matrix entspricht.\n\nX = dataset.iloc[:, :-1].values\n\niloc ist eine Methode, die pandas für DataFrames zur Verfügung stellt. In den eckigen Klammern wird angegeben, welche Werte einer Tabelle ausgewählt werden sollen. Stehen dort zwei kommaseparierte Werte, bezeichnet der erste die Zeilen, der zweite die Spalten.\n\n\n\n\n\n\nAufgabe\n\n\n\nErklären Sie, was es mit den Doppelpunkten auf sich hat und warum die Angabe für die Spalten mit -1 notiert ist!"
  },
  {
    "objectID": "machine-learning/preprocessing.html#abhängigen-vektor-bestimmen",
    "href": "machine-learning/preprocessing.html#abhängigen-vektor-bestimmen",
    "title": "9  Daten vorbereiten (data preprocessing)",
    "section": "9.5 Abhängigen Vektor bestimmen",
    "text": "9.5 Abhängigen Vektor bestimmen\nAnschließend wird die letzte Spalte als Vektor ausgewählt. Diese Werte sollen vorhergesagt werden.\n\ny = dataset.iloc[:, -1].values\n\nDie Anordnung der Features als Matrix kann mit einer einfachen Ausgabe dargestellt werden.\n\nprint(X)\n\n[['Frankreich' 44.0 72000.0]\n ['Griechenland' 27.0 48000.0]\n ['Deutschland' 30.0 54000.0]\n ['Griechenland' 38.0 61000.0]\n ['Deutschland' 40.0 nan]\n ['Frankreich' 35.0 58000.0]\n ['Griechenland' nan 52000.0]\n ['Frankreich' 48.0 79000.0]\n ['Deutschland' 50.0 83000.0]\n ['Frankreich' 37.0 67000.0]]\n\n\nEbenso die Gestalt der abhängigen Variable als Vektor.\n\nprint(y)\n\n['Nein' 'Ja' 'Nein' 'Nein' 'Ja' 'Ja' 'Nein' 'Ja' 'Nein' 'Ja']"
  },
  {
    "objectID": "machine-learning/preprocessing.html#fehlende-daten-berücksichtigen",
    "href": "machine-learning/preprocessing.html#fehlende-daten-berücksichtigen",
    "title": "9  Daten vorbereiten (data preprocessing)",
    "section": "9.6 Fehlende Daten berücksichtigen",
    "text": "9.6 Fehlende Daten berücksichtigen\nWenn wenige Daten fehlen, können diese Datensätze in der Regel ignoriert bzw. entfernt werden. Fehlen in vielen Datensätzen Daten, gibt es verschiedene Strategien, diese zu ersetzen. Eine davon ist, den Mittelwert aus den vorhandenen Daten zu bilden. Hierfür stellt scikit-learn ein Verfahren zur Verfügung.\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X[:, 1:3])\nX[:, 1:3] = imputer.transform(X[:, 1:3])\n\n\nprint(X)\n\n[['Frankreich' 44.0 72000.0]\n ['Griechenland' 27.0 48000.0]\n ['Deutschland' 30.0 54000.0]\n ['Griechenland' 38.0 61000.0]\n ['Deutschland' 40.0 63777.77777777778]\n ['Frankreich' 35.0 58000.0]\n ['Griechenland' 38.77777777777778 52000.0]\n ['Frankreich' 48.0 79000.0]\n ['Deutschland' 50.0 83000.0]\n ['Frankreich' 37.0 67000.0]]\n\n\n\n\n\n\n\n\nAufgabe\n\n\n\nRecherchieren Sie verwendeten Klassen und Methoden in der Dokumentation von scikit-learn."
  },
  {
    "objectID": "machine-learning/preprocessing.html#kategorien-in-den-daten-kodieren",
    "href": "machine-learning/preprocessing.html#kategorien-in-den-daten-kodieren",
    "title": "9  Daten vorbereiten (data preprocessing)",
    "section": "9.7 Kategorien in den Daten kodieren",
    "text": "9.7 Kategorien in den Daten kodieren\nDamit der Algorithmus die Daten schnell und eindeutig verarbeiten kann, müssen Textwerte als Zahlenwerte kodiert werden, hier also die Länder. Ein gängiges Verfahren ist hierbei, binäre Vektoren aus den möglichen Kombinationen der Kategorien zu erstellen. Bei diesem Vorgehen werden neue Spalten angelegt, die diese Vektoren abbilden. Lesen Sie hierzu auch den Artikel über One Hot Encoding, wie dieses Verfahren genannt wird.\nDa im vorliegenden Datenset sowohl in den unabhängigen als auch in der abhängigen Variable kategorische Daten vorliegen, ist der Vorgang zweimal notwendig.\n\n9.7.1 Die unabhängige Variable kodieren\nAuch hierfür werden wieder Methoden von scikit-learn verwendet.\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n\n\nprint(ct)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('encoder', OneHotEncoder(), [0])])\n\n\n\nprint(X)\n\n[[0.0 1.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [1.0 0.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [1.0 0.0 0.0 40.0 63777.77777777778]\n [0.0 1.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [0.0 1.0 0.0 48.0 79000.0]\n [1.0 0.0 0.0 50.0 83000.0]\n [0.0 1.0 0.0 37.0 67000.0]]\n\n\n\n\n9.7.2 Die abhängige Variable kodieren\nDa die Werte der abhängigen Variablen binär abgebildet werden können, ist hier One-Hot-Encoding nicht notwendig.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\n\n\nprint(y)\n\n[1 0 1 1 0 0 1 0 1 0]"
  },
  {
    "objectID": "machine-learning/preprocessing.html#daten-aufteilen-in-training--und-testset",
    "href": "machine-learning/preprocessing.html#daten-aufteilen-in-training--und-testset",
    "title": "9  Daten vorbereiten (data preprocessing)",
    "section": "9.8 Daten aufteilen in Training- und Testset",
    "text": "9.8 Daten aufteilen in Training- und Testset\nFür den eigentlichen Prozess des “Maschinenlernens” wird das Datenset in ein Trainingsset und ein Testset aufgeteilt.\nMit dem Trainingsset wird das Machine-Learning-Modell trainiert, mit dem Testset wird die Vorhersagegüte des Modells getestet. Hierbei wird so getan, als ob es sich bei den Testdaten um zukünftige reale Daten handelt.\nscikit-learn stellt auch hierfür ein Verfahren bereit.\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n\n\nprint(X_train)\n\n[[0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 40.0 63777.77777777778]\n [0.0 1.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 1.0 0.0 48.0 79000.0]\n [1.0 0.0 0.0 50.0 83000.0]\n [0.0 1.0 0.0 35.0 58000.0]]\n\n\n\nprint(X_test)\n\n[[1.0 0.0 0.0 30.0 54000.0]\n [0.0 1.0 0.0 37.0 67000.0]]\n\n\n\nprint(y_train)\n\n[1 0 1 1 0 0 1 0]\n\n\n\nprint(y_test)\n\n[1 0]"
  },
  {
    "objectID": "machine-learning/preprocessing.html#feature-scaling",
    "href": "machine-learning/preprocessing.html#feature-scaling",
    "title": "9  Daten vorbereiten (data preprocessing)",
    "section": "9.9 Feature Scaling",
    "text": "9.9 Feature Scaling\nFeature Scaling ist die Anpassung der unabhängigen Daten in einer Weise, dass sie alle im gleichen Verhältnis zueinander stehen. Dadurch wird vermieden, dass ein Feature andere Features dominiert.\nWichtig: Feature Scaling wird immer erst nach der Aufteilung des Datensets durchgeführt! Damit wird Informationsverlust bei den Testdaten vermieden.\n\n9.9.1 Normalisierung\nHier werden alle Werte in den Bereich zwischen 0 und 1 eingeordnet. Normalisierung wird angewendet, wenn es eine normale Verteilung in den meisten Features gibt.\n\n\n9.9.2 Standardisierung\nHierbei werden alle Werte in den Bereich von -3 und +3 eingeordnet. Standardisierung funktioniert immer, egal wie verschieden die Verteilung der Werte in den Features ist.\nTODO: Hier noch den Rechenweg\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = sc.transform(X_test[:, 3:])\n\n\nprint(X_train)\n\n[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n [1.0 0.0 0.0 -0.014117293757057777 -0.07013167641635372]\n [0.0 1.0 0.0 0.566708506533324 0.633562432710455]\n [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n [0.0 1.0 0.0 1.1475343068237058 1.232653363453549]\n [1.0 0.0 0.0 1.4379472069688968 1.5749910381638885]\n [0.0 1.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n\n\n\nprint(X_test)\n\n[[1.0 0.0 0.0 -1.4661817944830124 -0.9069571034860727]\n [0.0 1.0 0.0 -0.44973664397484414 0.2056403393225306]]"
  },
  {
    "objectID": "machine-learning/preprocessing.html#aufgaben",
    "href": "machine-learning/preprocessing.html#aufgaben",
    "title": "9  Daten vorbereiten (data preprocessing)",
    "section": "9.10 Aufgaben",
    "text": "9.10 Aufgaben\n\n\n\n\n\n\nNachvollziehen der verwendeten Klassen, Methoden und Eigenschaften von scikit-learn.\n\n\n\nRecherchieren Sie in der Dokumentation von scikit-learn, was Sie in diesem Beispiel verwendet haben.\n\n\n\n\n\n\n\n\nModell für Vorhersage entwickeln\n\n\n\n\nÜberlegen Sie, was für ein Modell Sie für diese Daten entwickeln müssen, um die Kaufabsichten von Klienten vorhersagen zu können.\nEntwickeln Sie das Modell."
  },
  {
    "objectID": "machine-learning/linear-regression.html",
    "href": "machine-learning/linear-regression.html",
    "title": "10  Einfache lineare Regression",
    "section": "",
    "text": "Bei der einfachen Linearen Regression geht es darum, einen Wert in Abhängigkeit von einem anderen Wert vorherzusagen. Bspw. kann die Frage gestellt werden, die Erfahrung und Gehalt zusammenhängen. Eine verständliche Einführung mit Beispielen finden Sie im Netz."
  },
  {
    "objectID": "machine-learning/linear-regression.html#beispiel-gehalt-bestimmen-in-abhängigkeit-von-der-berufserfahrung",
    "href": "machine-learning/linear-regression.html#beispiel-gehalt-bestimmen-in-abhängigkeit-von-der-berufserfahrung",
    "title": "10  Einfache lineare Regression",
    "section": "10.1 Beispiel: Gehalt bestimmen in Abhängigkeit von der Berufserfahrung",
    "text": "10.1 Beispiel: Gehalt bestimmen in Abhängigkeit von der Berufserfahrung\n\n10.1.1 Bibliotheken importieren\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n10.1.2 Daten importieren\n\ndataset = pd.read_csv(\"data/gehalt.csv\")\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n\n\n10.1.3 Daten aufteilen\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n\n\n10.1.4 Trainieren des Modells für Lineare Regression\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n\n10.1.5 Ergebnisse aus dem Testset vorhersagen\n\ny_pred = regressor.predict(X_test)\n\n\n\n10.1.6 Trainingergebnisse visualisieren\n\nplt.scatter(X_train, y_train, color = 'red')\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Gehalt vs. Erfahrung (Trainingset)')\nplt.xlabel('Berufserfahrung in Jahren')\nplt.ylabel('Gehalt')\nplt.show()\n\n\n\n\n\n\n10.1.7 Testergebnisse visualisieren\n\nplt.scatter(X_test, y_test, color = 'red')\n# Hier muss nichts ersetzt werden!\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Gehalt vs. Erfahrung (Testset)')\nplt.xlabel('Berufserfahrung in Jahren')\nplt.ylabel('Gehalt')\nplt.show()"
  },
  {
    "objectID": "machine-learning/linear-regression.html#eine-einfache-vorhersage-machen",
    "href": "machine-learning/linear-regression.html#eine-einfache-vorhersage-machen",
    "title": "10  Einfache lineare Regression",
    "section": "10.2 Eine einfache Vorhersage machen",
    "text": "10.2 Eine einfache Vorhersage machen\n\nprint(regressor.predict([[12]]))\n\n[138531.00067138]"
  },
  {
    "objectID": "machine-learning/linear-regression.html#die-finale-gleichung-der-regression-erhalten",
    "href": "machine-learning/linear-regression.html#die-finale-gleichung-der-regression-erhalten",
    "title": "10  Einfache lineare Regression",
    "section": "10.3 Die finale Gleichung der Regression erhalten",
    "text": "10.3 Die finale Gleichung der Regression erhalten\n\nprint(regressor.coef_)\n\n[9312.57512673]\n\n\n\nprint(regressor.intercept_)\n\n26780.09915062818\n\n\nDie finale Gleichung mit diesen Werten lautet daher:\n\\[\nGehalt = 9312,58 x JahreErfahrung + 26780,1\n\\]"
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html",
    "href": "machine-learning/multiple-linear-regression.html",
    "title": "11  Multiple lineare Regression",
    "section": "",
    "text": "Die multiple lineare Regression kommt zum Einsatz, wenn ein Wert aus mehreren unabhängigen Variablen vorhergesagt werden soll.\nFür das Verständnis des theoretischen Hintergrunds der multiplen linearen Regression ist diese Seite empfehlenswert."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#beispiel-50-startups",
    "href": "machine-learning/multiple-linear-regression.html#beispiel-50-startups",
    "title": "11  Multiple lineare Regression",
    "section": "11.1 Beispiel: 50 Startups",
    "text": "11.1 Beispiel: 50 Startups\nDer verwendete Datensatz für dieses Beispiel stammt von kaggle. In dem Anwendungsbeispiel geht es darum, Voraussagen über den Profit (abhängige Variable) zu treffen, in welche Startupstrategie es sich lohnt zu investieren."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#bibliotheken-importieren",
    "href": "machine-learning/multiple-linear-regression.html#bibliotheken-importieren",
    "title": "11  Multiple lineare Regression",
    "section": "11.2 Bibliotheken importieren",
    "text": "11.2 Bibliotheken importieren\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#daten-importieren",
    "href": "machine-learning/multiple-linear-regression.html#daten-importieren",
    "title": "11  Multiple lineare Regression",
    "section": "11.3 Daten importieren",
    "text": "11.3 Daten importieren\n\ndataset = pd.read_csv(\"data/50_Startups.csv\")\n\nDa dieses Datenset umfangreicher ist, werden nur die ersten Zeilen angezeigt.\n\ndataset.head()\n\n\n\n\n\n  \n    \n      \n      R&D Spend\n      Administration\n      Marketing Spend\n      State\n      Profit\n    \n  \n  \n    \n      0\n      165349.20\n      136897.80\n      471784.10\n      New York\n      192261.83\n    \n    \n      1\n      162597.70\n      151377.59\n      443898.53\n      California\n      191792.06\n    \n    \n      2\n      153441.51\n      101145.55\n      407934.54\n      Florida\n      191050.39\n    \n    \n      3\n      144372.41\n      118671.85\n      383199.62\n      New York\n      182901.99\n    \n    \n      4\n      142107.34\n      91391.77\n      366168.42\n      Florida\n      166187.94\n    \n  \n\n\n\n\nDie ersten vier Spalten sind in diesem Datenset die Features, die letzte Spalte Profit ist die abhängige Variable, die vorhergesagt werden soll."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#daten-aufteilen",
    "href": "machine-learning/multiple-linear-regression.html#daten-aufteilen",
    "title": "11  Multiple lineare Regression",
    "section": "11.4 Daten aufteilen",
    "text": "11.4 Daten aufteilen\nZunächst müssen die Daten wieder entsprechend aufgeteilt werden.\n\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values"
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#daten-aufbereiten",
    "href": "machine-learning/multiple-linear-regression.html#daten-aufbereiten",
    "title": "11  Multiple lineare Regression",
    "section": "11.5 Daten aufbereiten",
    "text": "11.5 Daten aufbereiten\nDa die Spalte State kategorische Daten enthält, muss sie für die weitere Verwendung mit One-Hot-Encoding transformiert werden."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#kategorische-daten-kodieren",
    "href": "machine-learning/multiple-linear-regression.html#kategorische-daten-kodieren",
    "title": "11  Multiple lineare Regression",
    "section": "11.6 Kategorische Daten kodieren",
    "text": "11.6 Kategorische Daten kodieren\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n\n\nprint(X)\n\n[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n [0.0 0.0 1.0 86419.7 153514.11 0.0]\n [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n [1.0 0.0 0.0 0.0 135426.92 0.0]\n [0.0 0.0 1.0 542.05 51743.15 0.0]\n [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nFeature Scaling muss bei multipler linearer Regression nicht angewendet werden, weil der Koeffizient in der Formal auf jedes Feature angewendet wird. Dadurch werden alle Features gleich gehandelt und kein Feature dominiert."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#daten-aufteilen-in-training--und-testset",
    "href": "machine-learning/multiple-linear-regression.html#daten-aufteilen-in-training--und-testset",
    "title": "11  Multiple lineare Regression",
    "section": "11.7 Daten aufteilen in Training- und Testset",
    "text": "11.7 Daten aufteilen in Training- und Testset\nFür den eigentlichen Prozess des “Maschinenlernens” wird das Datenset in ein Trainingsset und ein Testset aufgeteilt.\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#trainieren-des-modells",
    "href": "machine-learning/multiple-linear-regression.html#trainieren-des-modells",
    "title": "11  Multiple lineare Regression",
    "section": "11.8 Trainieren des Modells",
    "text": "11.8 Trainieren des Modells\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()"
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#eine-vorhersage-treffen",
    "href": "machine-learning/multiple-linear-regression.html#eine-vorhersage-treffen",
    "title": "11  Multiple lineare Regression",
    "section": "11.9 Eine Vorhersage treffen",
    "text": "11.9 Eine Vorhersage treffen\nWeil es jetzt mehrere Features gibt, ist das Zeichnen eine mehrdimensionalen Graphen nicht möglich. Daher werden im Folgenden die Profite aus den Trainingsdaten mit denen aus dem Testset verglichen. Hierbei kann die Güte des Modells erneut an der Abweichung der vorhergesagten zu den Testwerten gemessen werden.\n\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_pred),1)), 1))\n\n[[103015.2  103282.38]\n [132582.28 144259.4 ]\n [132447.74 146121.95]\n [ 71976.1   77798.83]\n [178537.48 191050.39]\n [116161.24 105008.31]\n [ 67851.69  81229.06]\n [ 98791.73  97483.56]\n [113969.44 110352.25]\n [167921.07 166187.94]]"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projekte",
    "section": "",
    "text": "Reprehenderit est ea labore nulla ullamco aliqua. Do minim magna est aliqua. Nostrud exercitation ea voluptate aliquip mollit non tempor ullamco quis sit tempor ad qui veniam. Et veniam ad enim laboris commodo anim. Lorem sit enim in tempor nisi commodo commodo cillum eiusmod sint ex anim. Dolor duis qui deserunt cupidatat pariatur elit nostrud aliqua ut sint nulla qui sint.\nOfficia Lorem sint voluptate dolore exercitation sit non ea anim minim laboris veniam veniam. Non aliqua eiusmod reprehenderit ut tempor ad consectetur Lorem. Nulla pariatur dolor sit officia veniam aliquip irure laboris. Nulla ipsum nostrud adipisicing labore sit. Dolore dolore pariatur sint minim aliquip veniam cupidatat reprehenderit nostrud. In laboris laboris tempor ex pariatur. Dolore anim ullamco quis duis mollit eiusmod nostrud qui in culpa ut ex.\nCillum reprehenderit proident mollit eu esse laborum laboris qui. Id tempor non adipisicing id veniam voluptate mollit enim culpa dolor eiusmod sint et. Dolore ea elit voluptate pariatur velit mollit magna eu dolor irure. Laborum consequat velit et adipisicing excepteur excepteur magna in tempor est ipsum exercitation irure. Non dolore excepteur nulla ut sint non exercitation ex ad anim voluptate voluptate cupidatat aliqua. Laboris labore minim deserunt anim tempor eiusmod ut. Duis nostrud cupidatat incididunt nostrud in aliquip est exercitation nulla aute sit deserunt incididunt.\nCulpa aliquip ad aliqua ex nulla amet minim. Veniam occaecat aliqua dolor qui ipsum sit culpa in ea est ad. Voluptate eu non culpa ea consectetur culpa et enim non labore consectetur id ad. Pariatur et ipsum nisi amet eu dolore in ex ipsum. Pariatur amet anim incididunt excepteur dolore excepteur esse amet reprehenderit aliquip incididunt mollit."
  },
  {
    "objectID": "projects/eierml.html",
    "href": "projects/eierml.html",
    "title": "14  EierML",
    "section": "",
    "text": "Repository klonen"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Quellen",
    "section": "",
    "text": "Kirste, Moritz, and Markus Schürholz. 2019. “Einleitung:\nEntwicklungswege zur KI.” In Künstliche Intelligenz,\nedited by Volker Wittpahl, 21–35. Berlin, Heidelberg:\nSpringer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-58042-4_1.\n\n\nStubbe, Julian, Jan Wessels, and Guido Zinke. 2019. “Neue\nIntelligenz, neue Ethik?” In Künstliche Intelligenz,\nedited by Volker Wittpahl, 239–54. Berlin, Heidelberg:\nSpringer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-58042-4_15."
  },
  {
    "objectID": "appendices/installation.html",
    "href": "appendices/installation.html",
    "title": "Appendix A — Installation",
    "section": "",
    "text": "Eu dolore proident sint voluptate. Elit consectetur labore culpa duis Lorem elit irure esse ad. Velit laboris velit proident aliquip deserunt nostrud reprehenderit in aute proident tempor non. Incididunt irure adipisicing qui occaecat id laboris commodo aliquip ea ipsum nostrud nulla aute.\nAute consequat commodo eu sit do non in irure ex nostrud nisi exercitation. Voluptate anim ad in excepteur labore dolor irure reprehenderit ipsum nulla aliquip ex nostrud consequat. Labore esse esse enim sit duis reprehenderit ea nostrud cupidatat officia ullamco magna aliquip elit. Aute anim eiusmod minim sunt culpa enim qui sit irure tempor commodo.\nIncididunt occaecat do incididunt ea nostrud sit ipsum nisi dolore eiusmod duis. Nisi velit id anim sunt duis tempor Lorem minim nostrud laborum exercitation. In id et eiusmod cupidatat veniam ex laboris laboris qui. Eu officia voluptate non cillum esse eiusmod nostrud eiusmod. Amet occaecat non est dolor laboris dolore ut laboris adipisicing qui adipisicing. Qui eu minim exercitation sunt laborum nisi qui aute.\nCulpa culpa quis velit laboris aliquip qui tempor fugiat. Ipsum ullamco quis Lorem labore fugiat. Aliqua eu anim ex laborum ad. Proident consequat sint dolor culpa excepteur pariatur dolor tempor laborum sunt laborum voluptate cupidatat laborum. Commodo sit esse voluptate labore eu non ea ut nisi ut sunt. Quis veniam in sint reprehenderit ut sunt occaecat sint."
  },
  {
    "objectID": "appendices/further.html",
    "href": "appendices/further.html",
    "title": "Appendix B — Weiterführende Informationen",
    "section": "",
    "text": "tbd"
  },
  {
    "objectID": "machine-learning/logistic-regression.html",
    "href": "machine-learning/logistic-regression.html",
    "title": "12  Logistische Regression",
    "section": "",
    "text": "Die logistische Regression ist eine Form der Regressionsanalyse, mit der Kriterien vorhergesagt werden können, die eindeutige Werte auf einer Skala haben. Beispiele dafür sind “angenommen” bzw. “abgelehnt” bei einer Aufnahmeprüfung (genau zwei Werte: binäre logistische Regression) oder “angenommen”, “abgelehnt” oder “Warteliste” (mehrere Werte: multinominale logistische Regression).\nDas Ergebnis einer Vorhersage ist immer eine Wahrscheinlichkeit, mit der ein Kritierium erfüllt ist.\nDer theoretische Hintergrund der Logistischen Regression wird sehr gut auf dieser Seite erklärt."
  },
  {
    "objectID": "machine-learning/logistic-regression.html#bibliotheken-importieren",
    "href": "machine-learning/logistic-regression.html#bibliotheken-importieren",
    "title": "12  Logistische Regression",
    "section": "12.1 Bibliotheken importieren",
    "text": "12.1 Bibliotheken importieren\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#daten-importieren",
    "href": "machine-learning/logistic-regression.html#daten-importieren",
    "title": "12  Logistische Regression",
    "section": "12.2 Daten importieren",
    "text": "12.2 Daten importieren\n\ndataset = pd.read_csv(\"data/Social_Network_Ads.csv\")\n\nDa dieses Datenset umfangreicher ist, werden nur die ersten Zeilen angezeigt.\n\ndataset.head()"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#featurematrix-auswählen",
    "href": "machine-learning/logistic-regression.html#featurematrix-auswählen",
    "title": "12  Logistische Regression",
    "section": "12.3 Featurematrix auswählen",
    "text": "12.3 Featurematrix auswählen\nZunächst werden die Features in einer Variable zusammengefasst, die einer Matrix entspricht.\n\nX = dataset.iloc[:, :-1].values"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#abhängigen-vektor-bestimmen",
    "href": "machine-learning/logistic-regression.html#abhängigen-vektor-bestimmen",
    "title": "12  Logistische Regression",
    "section": "12.4 Abhängigen Vektor bestimmen",
    "text": "12.4 Abhängigen Vektor bestimmen\nAnschließend wird die letzte Spalte als Vektor ausgewählt. Diese Werte sollen vorhergesagt werden.\n\ny = dataset.iloc[:, -1].values"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#fehlende-daten-berücksichtigen",
    "href": "machine-learning/logistic-regression.html#fehlende-daten-berücksichtigen",
    "title": "12  Logistische Regression",
    "section": "12.5 Fehlende Daten berücksichtigen",
    "text": "12.5 Fehlende Daten berücksichtigen\nWenn wenige Daten fehlen, können diese Datensätze in der Regel ignoriert bzw. entfernt werden. Fehlen in vielen Datensätzen Daten, gibt es verschiedene Strategien, diese zu ersetzen. Eine davon ist, den Mittelwert aus den vorhandenen Daten zu bilden. Hierfür stellt scikit-learn ein Verfahren zur Verfügung.\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X[:, 1:3])\nX[:, 1:3] = imputer.transform(X[:, 1:3])\n\n\nprint(X)\n\n[['Frankreich' 44.0 72000.0]\n ['Griechenland' 27.0 48000.0]\n ['Deutschland' 30.0 54000.0]\n ['Griechenland' 38.0 61000.0]\n ['Deutschland' 40.0 63777.77777777778]\n ['Frankreich' 35.0 58000.0]\n ['Griechenland' 38.77777777777778 52000.0]\n ['Frankreich' 48.0 79000.0]\n ['Deutschland' 50.0 83000.0]\n ['Frankreich' 37.0 67000.0]]\n\n\n\n\n\n\n\n\nAufgabe\n\n\n\nRecherchieren Sie verwendeten Klassen und Methoden in der Dokumentation von scikit-learn."
  },
  {
    "objectID": "machine-learning/logistic-regression.html#kategorien-in-den-daten-kodieren",
    "href": "machine-learning/logistic-regression.html#kategorien-in-den-daten-kodieren",
    "title": "12  Logistische Regression",
    "section": "12.6 Kategorien in den Daten kodieren",
    "text": "12.6 Kategorien in den Daten kodieren\nDamit der Algorithmus die Daten schnell und eindeutig verarbeiten kann, müssen Textwerte als Zahlenwerte kodiert werden, hier also die Länder. Ein gängiges Verfahren ist hierbei, binäre Vektoren aus den möglichen Kombinationen der Kategorien zu erstellen. Bei diesem Vorgehen werden neue Spalten angelegt, die diese Vektoren abbilden. Lesen Sie hierzu auch den Artikel über One Hot Encoding, wie dieses Verfahren genannt wird.\nDa im vorliegenden Datenset sowohl in den unabhängigen als auch in der abhängigen Variable kategorische Daten vorliegen, ist der Vorgang zweimal notwendig.\n\n12.6.1 Die unabhängige Variable kodieren\nAuch hierfür werden wieder Methoden von scikit-learn verwendet.\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n\n\nprint(ct)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('encoder', OneHotEncoder(), [0])])\n\n\n\nprint(X)\n\n[[0.0 1.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [1.0 0.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [1.0 0.0 0.0 40.0 63777.77777777778]\n [0.0 1.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [0.0 1.0 0.0 48.0 79000.0]\n [1.0 0.0 0.0 50.0 83000.0]\n [0.0 1.0 0.0 37.0 67000.0]]\n\n\n\n\n12.6.2 Die abhängige Variable kodieren\nDa die Werte der abhängigen Variablen binär abgebildet werden können, ist hier One-Hot-Encoding nicht notwendig.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\n\n\nprint(y)\n\n[1 0 1 1 0 0 1 0 1 0]"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#daten-aufteilen-in-training--und-testset",
    "href": "machine-learning/logistic-regression.html#daten-aufteilen-in-training--und-testset",
    "title": "12  Logistische Regression",
    "section": "12.5 Daten aufteilen in Training- und Testset",
    "text": "12.5 Daten aufteilen in Training- und Testset\nFür den eigentlichen Prozess des “Maschinenlernens” wird das Datenset in ein Trainingsset und ein Testset aufgeteilt.\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n\n\nprint(X_train)\n\n\nprint(X_test)\n\n\nprint(y_train)\n\n\nprint(y_test)"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#feature-scaling",
    "href": "machine-learning/logistic-regression.html#feature-scaling",
    "title": "12  Logistische Regression",
    "section": "12.6 Feature Scaling",
    "text": "12.6 Feature Scaling\nDas Feature Scaling ist für diese Anwendung nicht unbedingt notwendig, zum Üben kann es aber noch einmal durchgeführt werden. Dabei kommt wieder die Standardisierung zum Einsatz.\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n\nprint(X_train)\n\n\nprint(X_test)"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#das-model-trainieren",
    "href": "machine-learning/logistic-regression.html#das-model-trainieren",
    "title": "12  Logistische Regression",
    "section": "12.7 Das Model trainieren",
    "text": "12.7 Das Model trainieren\n\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#eine-vorhersage-machen",
    "href": "machine-learning/logistic-regression.html#eine-vorhersage-machen",
    "title": "12  Logistische Regression",
    "section": "12.8 Eine Vorhersage machen",
    "text": "12.8 Eine Vorhersage machen\nWichtig: Für die Vorhersage müssen die Daten an die neue Skala angepasst werden!\n\nclassifier.predict(sc.transform([[30,87000]]))"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#die-testergebnisse-vorhersagen",
    "href": "machine-learning/logistic-regression.html#die-testergebnisse-vorhersagen",
    "title": "12  Logistische Regression",
    "section": "12.9 Die Testergebnisse vorhersagen",
    "text": "12.9 Die Testergebnisse vorhersagen\n\ny_pred = classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_pred),1)), 1))"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#confusion-matrix-ausgeben",
    "href": "machine-learning/logistic-regression.html#confusion-matrix-ausgeben",
    "title": "12  Logistische Regression",
    "section": "12.10 Confusion Matrix ausgeben",
    "text": "12.10 Confusion Matrix ausgeben\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n# Die Rate der korrekten Vorhersagen\naccuracy_score(y_test, y_pred)"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#visualisierung-des-trainingsets",
    "href": "machine-learning/logistic-regression.html#visualisierung-des-trainingsets",
    "title": "12  Logistische Regression",
    "section": "12.11 Visualisierung des Trainingsets",
    "text": "12.11 Visualisierung des Trainingsets"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#visualisierung-des-testsets",
    "href": "machine-learning/logistic-regression.html#visualisierung-des-testsets",
    "title": "12  Logistische Regression",
    "section": "12.12 Visualisierung des Testsets",
    "text": "12.12 Visualisierung des Testsets"
  },
  {
    "objectID": "preparation/index.html",
    "href": "preparation/index.html",
    "title": "Fingerübungen",
    "section": "",
    "text": "Bevor es mit Machine Learning losgeht, empfehlen sich einige Fingerübungen mit zentralen Pythonbibliotheken."
  }
]