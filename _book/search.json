[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning mit Python",
    "section": "",
    "text": "Herzlich willkommen in diesem Crashkurs zu Machine Learning.\n\n\n\nQuelle: “A man and a woman teaching a giant computer old-fashioned” by DALL-E 2"
  },
  {
    "objectID": "introduction/index.html",
    "href": "introduction/index.html",
    "title": "Einführung",
    "section": "",
    "text": "Quelle: “Wall decorations with colorful butterflies” von __ drz __ on Unsplash"
  },
  {
    "objectID": "introduction/theory.html",
    "href": "introduction/theory.html",
    "title": "1  Statistische Grundlagen",
    "section": "",
    "text": "Die Grundlagen verschiedener statistischer Funktionen und Vorgehensweisen zeige ich entlang der sehr guten Einführung zu Machine Learning auf der Seite der W3School.\nDort stehen die folgenden Konzepte im Mittelpunkt:\nIn diesem Grundlagenskript arbeiten wir zunächst auf das Thema Regression hin, um anschließend noch Konzepte der Klassifizierung kennenzulernen."
  },
  {
    "objectID": "introduction/theory.html#decision-tree",
    "href": "introduction/theory.html#decision-tree",
    "title": "1  Statistische Grundlagen",
    "section": "1.1 Decision tree",
    "text": "1.1 Decision tree\n\nhttps://www.askpython.com/python/machine-learning-introduction\n\nProident tempor non exercitation qui. Qui magna commodo nostrud quis. Id nulla ex laboris elit ullamco ut sunt et cillum ut deserunt. Laboris anim veniam elit aliquip. Dolore anim voluptate eiusmod enim proident ea labore non id ex incididunt tempor dolor sit. Occaecat esse tempor proident elit laboris consequat cupidatat."
  },
  {
    "objectID": "introduction/theory.html#literatur-zur-einführung",
    "href": "introduction/theory.html#literatur-zur-einführung",
    "title": "1  Statistische Grundlagen",
    "section": "1.2 Literatur zur Einführung",
    "text": "1.2 Literatur zur Einführung\n\nKirste und Schürholz (2019)\nStubbe, Wessels, und Zinke (2019)\n\n\n\n\n\nKirste, Moritz, und Markus Schürholz. 2019. „Einleitung: Entwicklungswege zur KI“. In Künstliche Intelligenz, herausgegeben von Volker Wittpahl, 21–35. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-58042-4_1.\n\n\nStubbe, Julian, Jan Wessels, und Guido Zinke. 2019. „Neue Intelligenz, neue Ethik?“ In Künstliche Intelligenz, herausgegeben von Volker Wittpahl, 239–54. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-58042-4_15."
  },
  {
    "objectID": "introduction/jupyter-usage.html",
    "href": "introduction/jupyter-usage.html",
    "title": "1  Einführung in JupyterLab",
    "section": "",
    "text": "Das zentrale Werkzeug in diesem Kurs ist die Browsersoftware JupyterLab. Die folgenden Themen stehen dabei im Mittelpunkt:\nDie einschlägige JupyterLab-Dokumentation liefert zu all diesen Themen brauchbare Hinweise in englischer Sprache."
  },
  {
    "objectID": "introduction/find-data.html",
    "href": "introduction/find-data.html",
    "title": "2  Daten finden",
    "section": "",
    "text": "https://hub.packtpub.com/best-machine-learning-datasets-for-beginners/"
  },
  {
    "objectID": "introduction/pretrained-models.html",
    "href": "introduction/pretrained-models.html",
    "title": "3  Vortrainierte Modelle",
    "section": "",
    "text": "https://www.tensorflow.org/js/models\nhttps://firebase.google.com/docs/ml-kit\nhttps://tfhub.dev/"
  },
  {
    "objectID": "preparation/numpy.html",
    "href": "preparation/numpy.html",
    "title": "2  numpy",
    "section": "",
    "text": "numpy ist eine sehr schnelle Bibliothek für Python, mit der hauptsächlich Operationen auf mehrdimensionalen Arrays ausgeführt werden."
  },
  {
    "objectID": "preparation/numpy.html#einfache-statistische-funktionen",
    "href": "preparation/numpy.html#einfache-statistische-funktionen",
    "title": "2  numpy",
    "section": "2.1 Einfache statistische Funktionen",
    "text": "2.1 Einfache statistische Funktionen\nhttps://www.w3schools.com/python/python_ml_mean_median_mode.asp\n\n### Mean\n\n\n#!pip install numpy\n\n\nspeed = [99,86,87,88,111,86,103,87,94,78,77,85,86]\n\n\n2.1.1 Mean (Mittelwert)\n\nimport numpy as np\n\n\nx = np.median(speed)\nx\n\n87.0"
  },
  {
    "objectID": "preparation/numpy.html#übungen-zum-auswählen-von-daten-aus-einer-tabelle",
    "href": "preparation/numpy.html#übungen-zum-auswählen-von-daten-aus-einer-tabelle",
    "title": "2  numpy",
    "section": "2.3 Übungen zum Auswählen von Daten aus einer Tabelle",
    "text": "2.3 Übungen zum Auswählen von Daten aus einer Tabelle\nHier geht es vornehmlich um die Methode iloc in numpy und pandas.\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html?highlight=iloc#pandas.DataFrame.iloc"
  },
  {
    "objectID": "preparation/matplotlib.html",
    "href": "preparation/matplotlib.html",
    "title": "3  matplotlib",
    "section": "",
    "text": "matplotlib ist ein Standard, wenn es um die Visualisierung von Daten mit Python geht. In diesem Abschnitt Lernen Sie die Grundlagen kennen, wobei Sie sich am offiziellen Tutorial der Bibliothek orientieren."
  },
  {
    "objectID": "preparation/matplotlib.html#ein-erstes-beispiel",
    "href": "preparation/matplotlib.html#ein-erstes-beispiel",
    "title": "3  matplotlib",
    "section": "3.1 Ein erstes Beispiel",
    "text": "3.1 Ein erstes Beispiel\n\nimport matplotlib.pyplot as plt\nplt.plot([0, 2, 3, 4])\nplt.ylabel('some numbers')\nplt.show()"
  },
  {
    "objectID": "preparation/matplotlib.html#formatieren-der-visualisierung",
    "href": "preparation/matplotlib.html#formatieren-der-visualisierung",
    "title": "3  matplotlib",
    "section": "3.2 Formatieren der Visualisierung",
    "text": "3.2 Formatieren der Visualisierung\n\nplt.plot([1, 2, 3, 4], [1, 4, 9, 16], 'ro')\nplt.axis([0, 6, 0, 20])\nplt.show()"
  },
  {
    "objectID": "preparation/matplotlib.html#ein-beispiel-mit-numpy",
    "href": "preparation/matplotlib.html#ein-beispiel-mit-numpy",
    "title": "3  matplotlib",
    "section": "3.3 Ein Beispiel mit numpy",
    "text": "3.3 Ein Beispiel mit numpy\n\nimport numpy as np\n\n# evenly sampled time at 200ms intervals\nt = np.arange(0., 5., 0.2)\n\n# red dashes, blue squares and green triangles\nplt.plot(t, t, 'r--', t, t**2, 'bs', t, t**3, 'g^')\nplt.show()"
  },
  {
    "objectID": "preparation/matplotlib.html#aufgaben",
    "href": "preparation/matplotlib.html#aufgaben",
    "title": "3  matplotlib",
    "section": "3.4 Aufgaben",
    "text": "3.4 Aufgaben\n\n\n\n\n\n\nExperimentieren mit matplotlib\n\n\n\n\nLaden Sie das Tutorial als Notebook vom Ende der Tutorialseite herunter.\nBringen Sie es in Ihrem JupyterLab zum Laufen.\nExperimentieren Sie mit den Beispielen, wobei Sie die offzielle Dokumentation benutzen."
  },
  {
    "objectID": "preparation/pandas.html",
    "href": "preparation/pandas.html",
    "title": "4  pandas",
    "section": "",
    "text": "pandas ist der Standard für allgemeine Operationen zur Datenbereinigung und -vorbereitung geworden. Sie können mit pandas viele Dinge tun (und besser!), die Sie vielleicht bisher mit einem Tabellenkalkulationsprogramm erledigt haben."
  },
  {
    "objectID": "preparation/pandas.html#normalisierung-vs.-standardisierung",
    "href": "preparation/pandas.html#normalisierung-vs.-standardisierung",
    "title": "4  pandas",
    "section": "4.2 Normalisierung vs. Standardisierung",
    "text": "4.2 Normalisierung vs. Standardisierung\nhttps://www.statology.org/standardization-vs-normalization/"
  },
  {
    "objectID": "machine-learning/index.html",
    "href": "machine-learning/index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Für Deep Learning und künstliche neuronale Netze gibt es weitere spezialisierte und ausgereifte Bibliotheken, die in diesem Kurs nicht behandelt werden.\nZu empfehlen ist der Themenband “Künstliche Intelligenz” von Wittpahl (2019). Darin führen Kirste und Schürholz (2019) ein in die Entwicklung verschiedener Richtungen von KI und gehen auch auf das Machine Learning ein.\n\n\n\nQuelle: Crissy Jarvis on Unsplash\n\n\n\n\n\n\nKirste, Moritz, und Markus Schürholz. 2019. „Einleitung: Entwicklungswege zur KI“. In Künstliche Intelligenz, herausgegeben von Volker Wittpahl, 21–35. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-58042-4_1.\n\n\nWittpahl, Volker, Hrsg. 2019. Künstliche Intelligenz. Technologien  Anwendung  Gesellschaft. Berlin, Heidelberg: Springer Vieweg. https://link.springer.com/book/10.1007/978-3-662-58042-4."
  },
  {
    "objectID": "machine-learning/preprocessing.html",
    "href": "machine-learning/preprocessing.html",
    "title": "5  Daten vorbereiten",
    "section": "",
    "text": "Führen Sie die folgende Zelle aus, um zu überprüfen, dass alle notwendigen Bibliotheken installiert sind.\n\n#%pip install sklearn\n#%pip install numpy\n#%pip install pandas\n#%pip install matplotlib"
  },
  {
    "objectID": "machine-learning/preprocessing.html#bibliotheken-importieren",
    "href": "machine-learning/preprocessing.html#bibliotheken-importieren",
    "title": "5  Daten vorbereiten",
    "section": "5.2 Bibliotheken importieren",
    "text": "5.2 Bibliotheken importieren\nDie folgenden Bibliotheken brauchen Sie für die meisten Aufgaben. Ihr Import steht daher meistens am Anfang Ihrer Programme oder Notebooks.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "machine-learning/preprocessing.html#daten-importieren",
    "href": "machine-learning/preprocessing.html#daten-importieren",
    "title": "5  Daten vorbereiten",
    "section": "5.3 Daten importieren",
    "text": "5.3 Daten importieren\nDie Daten, die in diesem Beispiel als CSV-Datei vorliegen, wird mithilfe von pandas importiert.\n\ndataset = pd.read_csv(\"data/dataset.csv\")\n\nDas geladene Datenset kann hier im Notebook angezeigt werden.\n\ndataset\n\n\n\n\n\n  \n    \n      \n      Land\n      Alter\n      Gehalt\n      gekauft\n    \n  \n  \n    \n      0\n      Frankreich\n      44.0\n      72000.0\n      Nein\n    \n    \n      1\n      Griechenland\n      27.0\n      48000.0\n      Ja\n    \n    \n      2\n      Deutschland\n      30.0\n      54000.0\n      Nein\n    \n    \n      3\n      Griechenland\n      38.0\n      61000.0\n      Nein\n    \n    \n      4\n      Deutschland\n      40.0\n      NaN\n      Ja\n    \n    \n      5\n      Frankreich\n      35.0\n      58000.0\n      Ja\n    \n    \n      6\n      Griechenland\n      NaN\n      52000.0\n      Nein\n    \n    \n      7\n      Frankreich\n      48.0\n      79000.0\n      Ja\n    \n    \n      8\n      Deutschland\n      50.0\n      83000.0\n      Nein\n    \n    \n      9\n      Frankreich\n      37.0\n      67000.0\n      Ja\n    \n  \n\n\n\n\nFür die folgenden Operationen auf den Daten muss das Datenset in zwei Bereiche eingeteilt werden. Dabei sind sind die folgenden Gedanken leitend:\nDas zu entwickelnde Modell soll voraussagen können, ob ein Klient Kaufabsichten hat oder nicht. Dafür werden die Features Land, Alter und Gehalt zugrundegelegt. Diese Features sind die unabhängigen Variablen. Die abhängige Variable wiederum ist in der letzten Spalte gekauft zu finden. Sie hängt von den Werten der ersten drei Spalten ab.\nEs gilt also, ein Modell mit den Features der ersten drei Spalten zu trainieren, um eine Voraussage (prediction) für die Kaufabsicht treffen zu können.\nDie folgenden Anweisungen sind sehr allgemein formuliert, damit sie für weitere Aufgaben wiederverwendbar sind. Voraussetzung ist, dass die ersten Spalten eines Datensets die unabhängigen Variablen enthalten, während die abhängige Variable in der letzten Spalte steht."
  },
  {
    "objectID": "machine-learning/preprocessing.html#featurematrix-auswählen",
    "href": "machine-learning/preprocessing.html#featurematrix-auswählen",
    "title": "5  Daten vorbereiten",
    "section": "5.4 Featurematrix auswählen",
    "text": "5.4 Featurematrix auswählen\nZunächst werden die Features in einer Variable zusammengefasst, die einer Matrix entspricht.\n\nX = dataset.iloc[:, :-1].values\n\niloc ist eine Methode, die pandas für DataFrames zur Verfügung stellt. In den eckigen Klammern wird angegeben, welche Werte einer Tabelle ausgewählt werden sollen. Stehen dort zwei kommaseparierte Werte, bezeichnet der erste die Zeilen, der zweite die Spalten.\n\n\n\n\n\n\nAufgabe\n\n\n\nErklären Sie, was es mit den Doppelpunkten auf sich hat und warum die Angabe für die Spalten mit -1 notiert ist!"
  },
  {
    "objectID": "machine-learning/preprocessing.html#abhängigen-vektor-bestimmen",
    "href": "machine-learning/preprocessing.html#abhängigen-vektor-bestimmen",
    "title": "5  Daten vorbereiten",
    "section": "5.5 Abhängigen Vektor bestimmen",
    "text": "5.5 Abhängigen Vektor bestimmen\nAnschließend wird die letzte Spalte als Vektor ausgewählt. Diese Werte sollen vorhergesagt werden.\n\ny = dataset.iloc[:, -1].values\n\nDie Anordnung der Features als Matrix kann mit einer einfachen Ausgabe dargestellt werden.\n\nprint(X)\n\n[['Frankreich' 44.0 72000.0]\n ['Griechenland' 27.0 48000.0]\n ['Deutschland' 30.0 54000.0]\n ['Griechenland' 38.0 61000.0]\n ['Deutschland' 40.0 nan]\n ['Frankreich' 35.0 58000.0]\n ['Griechenland' nan 52000.0]\n ['Frankreich' 48.0 79000.0]\n ['Deutschland' 50.0 83000.0]\n ['Frankreich' 37.0 67000.0]]\n\n\nEbenso die Gestalt der abhängigen Variable als Vektor.\n\nprint(y)\n\n['Nein' 'Ja' 'Nein' 'Nein' 'Ja' 'Ja' 'Nein' 'Ja' 'Nein' 'Ja']"
  },
  {
    "objectID": "machine-learning/preprocessing.html#fehlende-daten-berücksichtigen",
    "href": "machine-learning/preprocessing.html#fehlende-daten-berücksichtigen",
    "title": "5  Daten vorbereiten",
    "section": "5.6 Fehlende Daten berücksichtigen",
    "text": "5.6 Fehlende Daten berücksichtigen\nWenn wenige Daten fehlen, können diese Datensätze in der Regel ignoriert bzw. entfernt werden. Fehlen in vielen Datensätzen Daten, gibt es verschiedene Strategien, diese zu ersetzen. Eine davon ist, den Mittelwert aus den vorhandenen Daten zu bilden. Hierfür stellt scikit-learn ein Verfahren zur Verfügung.\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X[:, 1:3])\nX[:, 1:3] = imputer.transform(X[:, 1:3])\n\n\nprint(X)\n\n[['Frankreich' 44.0 72000.0]\n ['Griechenland' 27.0 48000.0]\n ['Deutschland' 30.0 54000.0]\n ['Griechenland' 38.0 61000.0]\n ['Deutschland' 40.0 63777.77777777778]\n ['Frankreich' 35.0 58000.0]\n ['Griechenland' 38.77777777777778 52000.0]\n ['Frankreich' 48.0 79000.0]\n ['Deutschland' 50.0 83000.0]\n ['Frankreich' 37.0 67000.0]]\n\n\n\n\n\n\n\n\nAufgabe\n\n\n\nRecherchieren Sie verwendeten Klassen und Methoden in der Dokumentation von scikit-learn."
  },
  {
    "objectID": "machine-learning/preprocessing.html#kategorien-in-den-daten-kodieren",
    "href": "machine-learning/preprocessing.html#kategorien-in-den-daten-kodieren",
    "title": "5  Daten vorbereiten",
    "section": "5.7 Kategorien in den Daten kodieren",
    "text": "5.7 Kategorien in den Daten kodieren\nDamit der Algorithmus die Daten schnell und eindeutig verarbeiten kann, müssen Textwerte als Zahlenwerte kodiert werden, hier also die Länder. Ein gängiges Verfahren ist hierbei, binäre Vektoren aus den möglichen Kombinationen der Kategorien zu erstellen. Bei diesem Vorgehen werden neue Spalten angelegt, die diese Vektoren abbilden. Lesen Sie hierzu auch den Artikel über One Hot Encoding, wie dieses Verfahren genannt wird.\nDa im vorliegenden Datenset sowohl in den unabhängigen als auch in der abhängigen Variable kategorische Daten vorliegen, ist der Vorgang zweimal notwendig.\n\n5.7.1 Die unabhängige Variable kodieren\nAuch hierfür werden wieder Methoden von scikit-learn verwendet.\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n\n\nprint(ct)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('encoder', OneHotEncoder(), [0])])\n\n\n\nprint(X)\n\n[[0.0 1.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [1.0 0.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [1.0 0.0 0.0 40.0 63777.77777777778]\n [0.0 1.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [0.0 1.0 0.0 48.0 79000.0]\n [1.0 0.0 0.0 50.0 83000.0]\n [0.0 1.0 0.0 37.0 67000.0]]\n\n\n\n\n5.7.2 Die abhängige Variable kodieren\nDa die Werte der abhängigen Variablen binär abgebildet werden können, ist hier One-Hot-Encoding nicht notwendig.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\n\n\nprint(y)\n\n[1 0 1 1 0 0 1 0 1 0]"
  },
  {
    "objectID": "machine-learning/preprocessing.html#daten-aufteilen-in-training--und-testset",
    "href": "machine-learning/preprocessing.html#daten-aufteilen-in-training--und-testset",
    "title": "5  Daten vorbereiten",
    "section": "5.8 Daten aufteilen in Training- und Testset",
    "text": "5.8 Daten aufteilen in Training- und Testset\nFür den eigentlichen Prozess des “Maschinenlernens” wird das Datenset in ein Trainingsset und ein Testset aufgeteilt.\nMit dem Trainingsset wird das Machine-Learning-Modell trainiert, mit dem Testset wird die Vorhersagegüte des Modells getestet. Hierbei wird so getan, als ob es sich bei den Testdaten um zukünftige reale Daten handelt.\nscikit-learn stellt auch hierfür ein Verfahren bereit.\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n\n\nprint(X_train)\n\n[[0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 40.0 63777.77777777778]\n [0.0 1.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 1.0 0.0 48.0 79000.0]\n [1.0 0.0 0.0 50.0 83000.0]\n [0.0 1.0 0.0 35.0 58000.0]]\n\n\n\nprint(X_test)\n\n[[1.0 0.0 0.0 30.0 54000.0]\n [0.0 1.0 0.0 37.0 67000.0]]\n\n\n\nprint(y_train)\n\n[1 0 1 1 0 0 1 0]\n\n\n\nprint(y_test)\n\n[1 0]"
  },
  {
    "objectID": "machine-learning/preprocessing.html#feature-scaling",
    "href": "machine-learning/preprocessing.html#feature-scaling",
    "title": "5  Daten vorbereiten",
    "section": "5.9 Feature Scaling",
    "text": "5.9 Feature Scaling\nFeature Scaling ist die Anpassung der unabhängigen Daten in einer Weise, dass sie alle im gleichen Verhältnis zueinander stehen. Dadurch wird vermieden, dass ein Feature andere Features dominiert. Im Folgenden wird das Verfahren der Standardisierung angewendet.\nWichtig: Feature Scaling wird immer erst nach der Aufteilung des Datensets durchgeführt! Damit wird Informationsverlust bei den Testdaten vermieden.\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = sc.transform(X_test[:, 3:])\n\n\nprint(X_train)\n\n[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n [1.0 0.0 0.0 -0.014117293757057777 -0.07013167641635372]\n [0.0 1.0 0.0 0.566708506533324 0.633562432710455]\n [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n [0.0 1.0 0.0 1.1475343068237058 1.232653363453549]\n [1.0 0.0 0.0 1.4379472069688968 1.5749910381638885]\n [0.0 1.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n\n\n\nprint(X_test)\n\n[[1.0 0.0 0.0 -1.4661817944830124 -0.9069571034860727]\n [0.0 1.0 0.0 -0.44973664397484414 0.2056403393225306]]"
  },
  {
    "objectID": "machine-learning/preprocessing.html#aufgaben",
    "href": "machine-learning/preprocessing.html#aufgaben",
    "title": "5  Daten vorbereiten",
    "section": "5.10 Aufgaben",
    "text": "5.10 Aufgaben\n\n\n\n\n\n\nNachvollziehen der verwendeten Klassen, Methoden und Eigenschaften von scikit-learn.\n\n\n\nRecherchieren Sie in der Dokumentation von scikit-learn, was Sie in diesem Beispiel verwendet haben.\n\n\n\n\n\n\n\n\nModell für Vorhersage entwickeln\n\n\n\n\nÜberlegen Sie, was für ein Modell Sie für diese Daten entwickeln müssen, um die Kaufabsichten von Klienten vorhersagen zu können.\nEntscheiden Sie sich erst für ein Verfahren, nachdem Sie die lineare, die multiple und die logistische Regression in den folgenden Kapiteln kennengelernt haben.\n\n\n\n\n\n\n\n\n\nMehr über Feature Scaling erfahren\n\n\n\nLesen Sie mehr über Feature Scaling und die verschiedenen Möglichkeiten von sklearn"
  },
  {
    "objectID": "machine-learning/linear-regression.html",
    "href": "machine-learning/linear-regression.html",
    "title": "6  Einfache lineare Regression",
    "section": "",
    "text": "Bei der einfachen Linearen Regression geht es darum, einen Wert in Abhängigkeit von einem anderen Wert vorherzusagen. Bspw. kann die Frage gestellt werden, die Erfahrung und Gehalt zusammenhängen. Eine verständliche Einführung mit Beispielen finden Sie als Video im Netz."
  },
  {
    "objectID": "machine-learning/linear-regression.html#beispiel-gehalt-bestimmen-in-abhängigkeit-von-der-berufserfahrung",
    "href": "machine-learning/linear-regression.html#beispiel-gehalt-bestimmen-in-abhängigkeit-von-der-berufserfahrung",
    "title": "6  Einfache lineare Regression",
    "section": "6.1 Beispiel: Gehalt bestimmen in Abhängigkeit von der Berufserfahrung",
    "text": "6.1 Beispiel: Gehalt bestimmen in Abhängigkeit von der Berufserfahrung\n\n6.1.1 Bibliotheken importieren\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n6.1.2 Daten importieren\n\ndataset = pd.read_csv(\"data/gehalt.csv\")\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n\n\n6.1.3 Daten aufteilen\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n\n\n6.1.4 Trainieren des Modells für Lineare Regression\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n\n6.1.5 Ergebnisse aus dem Testset vorhersagen\n\ny_pred = regressor.predict(X_test)\n\n\n\n6.1.6 Trainingergebnisse visualisieren\n\nplt.scatter(X_train, y_train, color = 'red')\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Gehalt vs. Erfahrung (Trainingset)')\nplt.xlabel('Berufserfahrung in Jahren')\nplt.ylabel('Gehalt')\nplt.show()\n\n\n\n\n\n\n6.1.7 Testergebnisse visualisieren\n\nplt.scatter(X_test, y_test, color = 'red')\n# Hier muss nichts ersetzt werden!\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Gehalt vs. Erfahrung (Testset)')\nplt.xlabel('Berufserfahrung in Jahren')\nplt.ylabel('Gehalt')\nplt.show()"
  },
  {
    "objectID": "machine-learning/linear-regression.html#eine-einfache-vorhersage-machen",
    "href": "machine-learning/linear-regression.html#eine-einfache-vorhersage-machen",
    "title": "6  Einfache lineare Regression",
    "section": "6.2 Eine einfache Vorhersage machen",
    "text": "6.2 Eine einfache Vorhersage machen\n\nprint(regressor.predict([[12]]))\n\n[138531.00067138]"
  },
  {
    "objectID": "machine-learning/linear-regression.html#die-finale-gleichung-der-regression-erhalten",
    "href": "machine-learning/linear-regression.html#die-finale-gleichung-der-regression-erhalten",
    "title": "6  Einfache lineare Regression",
    "section": "6.3 Die finale Gleichung der Regression erhalten",
    "text": "6.3 Die finale Gleichung der Regression erhalten\n\nprint(regressor.coef_)\n\n[9312.57512673]\n\n\n\nprint(regressor.intercept_)\n\n26780.09915062818\n\n\nDie finale Gleichung mit diesen Werten lautet daher:\n\\[\nGehalt = 9312,58 x JahreErfahrung + 26780,1\n\\]"
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html",
    "href": "machine-learning/multiple-linear-regression.html",
    "title": "7  Multiple lineare Regression",
    "section": "",
    "text": "Die multiple lineare Regression kommt zum Einsatz, wenn ein Wert aus mehreren unabhängigen Variablen vorhergesagt werden soll.\nFür das Verständnis des theoretischen Hintergrunds der multiplen linearen Regression ist diese Seite empfehlenswert."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#beispiel-50-startups",
    "href": "machine-learning/multiple-linear-regression.html#beispiel-50-startups",
    "title": "7  Multiple lineare Regression",
    "section": "7.1 Beispiel: 50 Startups",
    "text": "7.1 Beispiel: 50 Startups\nDer verwendete Datensatz für dieses Beispiel stammt von kaggle. In dem Anwendungsbeispiel geht es darum, Voraussagen über den Profit (abhängige Variable) zu treffen, in welche Startupstrategie es sich lohnt zu investieren."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#bibliotheken-importieren",
    "href": "machine-learning/multiple-linear-regression.html#bibliotheken-importieren",
    "title": "7  Multiple lineare Regression",
    "section": "7.2 Bibliotheken importieren",
    "text": "7.2 Bibliotheken importieren\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#daten-importieren",
    "href": "machine-learning/multiple-linear-regression.html#daten-importieren",
    "title": "7  Multiple lineare Regression",
    "section": "7.3 Daten importieren",
    "text": "7.3 Daten importieren\n\ndataset = pd.read_csv(\"data/50_Startups.csv\")\n\nDa dieses Datenset umfangreicher ist, werden nur die ersten Zeilen angezeigt.\n\ndataset.head()\n\n\n\n\n\n  \n    \n      \n      R&D Spend\n      Administration\n      Marketing Spend\n      State\n      Profit\n    \n  \n  \n    \n      0\n      165349.20\n      136897.80\n      471784.10\n      New York\n      192261.83\n    \n    \n      1\n      162597.70\n      151377.59\n      443898.53\n      California\n      191792.06\n    \n    \n      2\n      153441.51\n      101145.55\n      407934.54\n      Florida\n      191050.39\n    \n    \n      3\n      144372.41\n      118671.85\n      383199.62\n      New York\n      182901.99\n    \n    \n      4\n      142107.34\n      91391.77\n      366168.42\n      Florida\n      166187.94\n    \n  \n\n\n\n\nDie ersten vier Spalten sind in diesem Datenset die Features, die letzte Spalte Profit ist die abhängige Variable, die vorhergesagt werden soll."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#daten-aufteilen",
    "href": "machine-learning/multiple-linear-regression.html#daten-aufteilen",
    "title": "7  Multiple lineare Regression",
    "section": "7.4 Daten aufteilen",
    "text": "7.4 Daten aufteilen\nZunächst müssen die Daten wieder entsprechend aufgeteilt werden.\n\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values"
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#daten-aufbereiten",
    "href": "machine-learning/multiple-linear-regression.html#daten-aufbereiten",
    "title": "7  Multiple lineare Regression",
    "section": "7.5 Daten aufbereiten",
    "text": "7.5 Daten aufbereiten\nDa die Spalte State kategorische Daten enthält, muss sie für die weitere Verwendung mit One-Hot-Encoding transformiert werden."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#kategorische-daten-kodieren",
    "href": "machine-learning/multiple-linear-regression.html#kategorische-daten-kodieren",
    "title": "7  Multiple lineare Regression",
    "section": "7.6 Kategorische Daten kodieren",
    "text": "7.6 Kategorische Daten kodieren\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n\n\nprint(X)\n\n[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n [0.0 0.0 1.0 86419.7 153514.11 0.0]\n [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n [1.0 0.0 0.0 0.0 135426.92 0.0]\n [0.0 0.0 1.0 542.05 51743.15 0.0]\n [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nFeature Scaling muss bei multipler linearer Regression nicht angewendet werden, weil der Koeffizient in der Formal auf jedes Feature angewendet wird. Dadurch werden alle Features gleich gehandelt und kein Feature dominiert."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#daten-aufteilen-in-training--und-testset",
    "href": "machine-learning/multiple-linear-regression.html#daten-aufteilen-in-training--und-testset",
    "title": "7  Multiple lineare Regression",
    "section": "7.7 Daten aufteilen in Training- und Testset",
    "text": "7.7 Daten aufteilen in Training- und Testset\nFür den eigentlichen Prozess des “Maschinenlernens” wird das Datenset in ein Trainingsset und ein Testset aufgeteilt.\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#trainieren-des-modells",
    "href": "machine-learning/multiple-linear-regression.html#trainieren-des-modells",
    "title": "7  Multiple lineare Regression",
    "section": "7.8 Trainieren des Modells",
    "text": "7.8 Trainieren des Modells\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()"
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#eine-vorhersage-treffen",
    "href": "machine-learning/multiple-linear-regression.html#eine-vorhersage-treffen",
    "title": "7  Multiple lineare Regression",
    "section": "7.9 Eine Vorhersage treffen",
    "text": "7.9 Eine Vorhersage treffen\nWeil es jetzt mehrere Features gibt, ist das Zeichnen eine mehrdimensionalen Graphen nicht möglich. Daher werden im Folgenden die Profite aus den Trainingsdaten mit denen aus dem Testset verglichen. Hierbei kann die Güte des Modells erneut an der Abweichung der vorhergesagten zu den Testwerten gemessen werden.\n\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_pred),1)), 1))\n\n[[103015.2  103282.38]\n [132582.28 144259.4 ]\n [132447.74 146121.95]\n [ 71976.1   77798.83]\n [178537.48 191050.39]\n [116161.24 105008.31]\n [ 67851.69  81229.06]\n [ 98791.73  97483.56]\n [113969.44 110352.25]\n [167921.07 166187.94]]"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projekte",
    "section": "",
    "text": "Reprehenderit est ea labore nulla ullamco aliqua. Do minim magna est aliqua. Nostrud exercitation ea voluptate aliquip mollit non tempor ullamco quis sit tempor ad qui veniam. Et veniam ad enim laboris commodo anim. Lorem sit enim in tempor nisi commodo commodo cillum eiusmod sint ex anim. Dolor duis qui deserunt cupidatat pariatur elit nostrud aliqua ut sint nulla qui sint.\nOfficia Lorem sint voluptate dolore exercitation sit non ea anim minim laboris veniam veniam. Non aliqua eiusmod reprehenderit ut tempor ad consectetur Lorem. Nulla pariatur dolor sit officia veniam aliquip irure laboris. Nulla ipsum nostrud adipisicing labore sit. Dolore dolore pariatur sint minim aliquip veniam cupidatat reprehenderit nostrud. In laboris laboris tempor ex pariatur. Dolore anim ullamco quis duis mollit eiusmod nostrud qui in culpa ut ex.\nCillum reprehenderit proident mollit eu esse laborum laboris qui. Id tempor non adipisicing id veniam voluptate mollit enim culpa dolor eiusmod sint et. Dolore ea elit voluptate pariatur velit mollit magna eu dolor irure. Laborum consequat velit et adipisicing excepteur excepteur magna in tempor est ipsum exercitation irure. Non dolore excepteur nulla ut sint non exercitation ex ad anim voluptate voluptate cupidatat aliqua. Laboris labore minim deserunt anim tempor eiusmod ut. Duis nostrud cupidatat incididunt nostrud in aliquip est exercitation nulla aute sit deserunt incididunt.\nCulpa aliquip ad aliqua ex nulla amet minim. Veniam occaecat aliqua dolor qui ipsum sit culpa in ea est ad. Voluptate eu non culpa ea consectetur culpa et enim non labore consectetur id ad. Pariatur et ipsum nisi amet eu dolore in ex ipsum. Pariatur amet anim incididunt excepteur dolore excepteur esse amet reprehenderit aliquip incididunt mollit."
  },
  {
    "objectID": "projects/eierml.html",
    "href": "projects/eierml.html",
    "title": "14  EierML",
    "section": "",
    "text": "Repository klonen"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Kirste, Moritz, and Markus Schürholz. 2019. “Einleitung:\nEntwicklungswege zur KI.” In Künstliche Intelligenz,\nedited by Volker Wittpahl, 21–35. Berlin, Heidelberg:\nSpringer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-58042-4_1.\n\n\nWittpahl, Volker, ed. 2019. Künstliche Intelligenz. Technologien\n Anwendung  Gesellschaft. Berlin,\nHeidelberg: Springer Vieweg. https://link.springer.com/book/10.1007/978-3-662-58042-4."
  },
  {
    "objectID": "appendices/installation.html",
    "href": "appendices/installation.html",
    "title": "Appendix A — Installation",
    "section": "",
    "text": "Eu dolore proident sint voluptate. Elit consectetur labore culpa duis Lorem elit irure esse ad. Velit laboris velit proident aliquip deserunt nostrud reprehenderit in aute proident tempor non. Incididunt irure adipisicing qui occaecat id laboris commodo aliquip ea ipsum nostrud nulla aute.\nAute consequat commodo eu sit do non in irure ex nostrud nisi exercitation. Voluptate anim ad in excepteur labore dolor irure reprehenderit ipsum nulla aliquip ex nostrud consequat. Labore esse esse enim sit duis reprehenderit ea nostrud cupidatat officia ullamco magna aliquip elit. Aute anim eiusmod minim sunt culpa enim qui sit irure tempor commodo.\nIncididunt occaecat do incididunt ea nostrud sit ipsum nisi dolore eiusmod duis. Nisi velit id anim sunt duis tempor Lorem minim nostrud laborum exercitation. In id et eiusmod cupidatat veniam ex laboris laboris qui. Eu officia voluptate non cillum esse eiusmod nostrud eiusmod. Amet occaecat non est dolor laboris dolore ut laboris adipisicing qui adipisicing. Qui eu minim exercitation sunt laborum nisi qui aute.\nCulpa culpa quis velit laboris aliquip qui tempor fugiat. Ipsum ullamco quis Lorem labore fugiat. Aliqua eu anim ex laborum ad. Proident consequat sint dolor culpa excepteur pariatur dolor tempor laborum sunt laborum voluptate cupidatat laborum. Commodo sit esse voluptate labore eu non ea ut nisi ut sunt. Quis veniam in sint reprehenderit ut sunt occaecat sint."
  },
  {
    "objectID": "appendices/further.html",
    "href": "appendices/further.html",
    "title": "Appendix B — Weiterführende Informationen",
    "section": "",
    "text": "tbd"
  },
  {
    "objectID": "machine-learning/logistic-regression.html",
    "href": "machine-learning/logistic-regression.html",
    "title": "8  Logistische Regression",
    "section": "",
    "text": "Die logistische Regression ist eine Form der Regressionsanalyse, mit der Kriterien vorhergesagt werden können, die eindeutige Werte auf einer Skala haben. Beispiele dafür sind “angenommen” bzw. “abgelehnt” bei einer Aufnahmeprüfung (genau zwei Werte: binäre logistische Regression) oder “angenommen”, “abgelehnt” oder “Warteliste” (mehrere Werte: multinominale logistische Regression).\nDas Ergebnis einer Vorhersage ist immer eine Wahrscheinlichkeit, mit der ein Kritierium erfüllt ist.\nDer theoretische Hintergrund der Logistischen Regression wird sehr gut auf dieser Seite in Form von Video und Text erklärt."
  },
  {
    "objectID": "machine-learning/logistic-regression.html#bibliotheken-importieren",
    "href": "machine-learning/logistic-regression.html#bibliotheken-importieren",
    "title": "8  Logistische Regression",
    "section": "8.1 Bibliotheken importieren",
    "text": "8.1 Bibliotheken importieren\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#daten-importieren",
    "href": "machine-learning/logistic-regression.html#daten-importieren",
    "title": "8  Logistische Regression",
    "section": "8.2 Daten importieren",
    "text": "8.2 Daten importieren\n\ndataset = pd.read_csv(\"data/Social_Network_Ads.csv\")\n\nDa dieses Datenset umfangreicher ist, werden nur die ersten Zeilen angezeigt.\n\ndataset.head(10)\n\n\n\n\n\n  \n    \n      \n      Age\n      EstimatedSalary\n      Purchased\n    \n  \n  \n    \n      0\n      19\n      19000\n      0\n    \n    \n      1\n      35\n      20000\n      0\n    \n    \n      2\n      26\n      43000\n      0\n    \n    \n      3\n      27\n      57000\n      0\n    \n    \n      4\n      19\n      76000\n      0\n    \n    \n      5\n      27\n      58000\n      0\n    \n    \n      6\n      27\n      84000\n      0\n    \n    \n      7\n      32\n      150000\n      1\n    \n    \n      8\n      25\n      33000\n      0\n    \n    \n      9\n      35\n      65000\n      0"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#featurematrix-auswählen",
    "href": "machine-learning/logistic-regression.html#featurematrix-auswählen",
    "title": "8  Logistische Regression",
    "section": "8.3 Featurematrix auswählen",
    "text": "8.3 Featurematrix auswählen\nZunächst werden die Features in einer Variable zusammengefasst, die einer Matrix entspricht.\n\nX = dataset.iloc[:, :-1].values"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#abhängigen-vektor-bestimmen",
    "href": "machine-learning/logistic-regression.html#abhängigen-vektor-bestimmen",
    "title": "8  Logistische Regression",
    "section": "8.4 Abhängigen Vektor bestimmen",
    "text": "8.4 Abhängigen Vektor bestimmen\nAnschließend wird die letzte Spalte als Vektor ausgewählt. Diese Werte sollen vorhergesagt werden.\n\ny = dataset.iloc[:, -1].values"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#fehlende-daten-berücksichtigen",
    "href": "machine-learning/logistic-regression.html#fehlende-daten-berücksichtigen",
    "title": "12  Logistische Regression",
    "section": "12.5 Fehlende Daten berücksichtigen",
    "text": "12.5 Fehlende Daten berücksichtigen\nWenn wenige Daten fehlen, können diese Datensätze in der Regel ignoriert bzw. entfernt werden. Fehlen in vielen Datensätzen Daten, gibt es verschiedene Strategien, diese zu ersetzen. Eine davon ist, den Mittelwert aus den vorhandenen Daten zu bilden. Hierfür stellt scikit-learn ein Verfahren zur Verfügung.\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X[:, 1:3])\nX[:, 1:3] = imputer.transform(X[:, 1:3])\n\n\nprint(X)\n\n[['Frankreich' 44.0 72000.0]\n ['Griechenland' 27.0 48000.0]\n ['Deutschland' 30.0 54000.0]\n ['Griechenland' 38.0 61000.0]\n ['Deutschland' 40.0 63777.77777777778]\n ['Frankreich' 35.0 58000.0]\n ['Griechenland' 38.77777777777778 52000.0]\n ['Frankreich' 48.0 79000.0]\n ['Deutschland' 50.0 83000.0]\n ['Frankreich' 37.0 67000.0]]\n\n\n\n\n\n\n\n\nAufgabe\n\n\n\nRecherchieren Sie verwendeten Klassen und Methoden in der Dokumentation von scikit-learn."
  },
  {
    "objectID": "machine-learning/logistic-regression.html#kategorien-in-den-daten-kodieren",
    "href": "machine-learning/logistic-regression.html#kategorien-in-den-daten-kodieren",
    "title": "12  Logistische Regression",
    "section": "12.6 Kategorien in den Daten kodieren",
    "text": "12.6 Kategorien in den Daten kodieren\nDamit der Algorithmus die Daten schnell und eindeutig verarbeiten kann, müssen Textwerte als Zahlenwerte kodiert werden, hier also die Länder. Ein gängiges Verfahren ist hierbei, binäre Vektoren aus den möglichen Kombinationen der Kategorien zu erstellen. Bei diesem Vorgehen werden neue Spalten angelegt, die diese Vektoren abbilden. Lesen Sie hierzu auch den Artikel über One Hot Encoding, wie dieses Verfahren genannt wird.\nDa im vorliegenden Datenset sowohl in den unabhängigen als auch in der abhängigen Variable kategorische Daten vorliegen, ist der Vorgang zweimal notwendig.\n\n12.6.1 Die unabhängige Variable kodieren\nAuch hierfür werden wieder Methoden von scikit-learn verwendet.\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n\n\nprint(ct)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('encoder', OneHotEncoder(), [0])])\n\n\n\nprint(X)\n\n[[0.0 1.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [1.0 0.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [1.0 0.0 0.0 40.0 63777.77777777778]\n [0.0 1.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [0.0 1.0 0.0 48.0 79000.0]\n [1.0 0.0 0.0 50.0 83000.0]\n [0.0 1.0 0.0 37.0 67000.0]]\n\n\n\n\n12.6.2 Die abhängige Variable kodieren\nDa die Werte der abhängigen Variablen binär abgebildet werden können, ist hier One-Hot-Encoding nicht notwendig.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\n\n\nprint(y)\n\n[1 0 1 1 0 0 1 0 1 0]"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#daten-aufteilen-in-training--und-testset",
    "href": "machine-learning/logistic-regression.html#daten-aufteilen-in-training--und-testset",
    "title": "8  Logistische Regression",
    "section": "8.5 Daten aufteilen in Training- und Testset",
    "text": "8.5 Daten aufteilen in Training- und Testset\nFür den eigentlichen Prozess des “Maschinenlernens” wird das Datenset in ein Trainingsset und ein Testset aufgeteilt.\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n\n\nprint(X_train)\n\n[[    20  49000]\n [    46  88000]\n [    31  34000]\n [    47  30000]\n [    35  50000]\n [    39  96000]\n [    33 113000]\n [    49  86000]\n [    45  79000]\n [    44  39000]\n [    41  59000]\n [    42  53000]\n [    35  73000]\n [    41  72000]\n [    27  96000]\n [    30 116000]\n [    41  52000]\n [    41  52000]\n [    20  82000]\n [    46  41000]\n [    27  31000]\n [    35  71000]\n [    49  28000]\n [    35  91000]\n [    37  75000]\n [    32 117000]\n [    36  75000]\n [    20  86000]\n [    38  50000]\n [    49  36000]\n [    40  65000]\n [    37  77000]\n [    60  46000]\n [    48 138000]\n [    40  71000]\n [    36  63000]\n [    26  81000]\n [    33  31000]\n [    41  51000]\n [    46  74000]\n [    18  82000]\n [    37  33000]\n [    35  53000]\n [    28  59000]\n [    37  71000]\n [    18  44000]\n [    38  61000]\n [    35  65000]\n [    31  66000]\n [    47  25000]\n [    42 104000]\n [    19  19000]\n [    21  72000]\n [    28  32000]\n [    52 150000]\n [    53 104000]\n [    25  80000]\n [    26  72000]\n [    26  15000]\n [    40 142000]\n [    35  38000]\n [    57 122000]\n [    41  87000]\n [    24  89000]\n [    37  52000]\n [    35 108000]\n [    32 100000]\n [    35 147000]\n [    19  26000]\n [    46  82000]\n [    47 105000]\n [    45  45000]\n [    38  51000]\n [    37  93000]\n [    29  43000]\n [    41  30000]\n [    40  60000]\n [    27  88000]\n [    27  90000]\n [    39  71000]\n [    23  28000]\n [    51 146000]\n [    23  63000]\n [    37  80000]\n [    40  47000]\n [    48  29000]\n [    35  59000]\n [    26  30000]\n [    39 106000]\n [    28  84000]\n [    59  76000]\n [    40  57000]\n [    35  97000]\n [    26  86000]\n [    41  63000]\n [    29  47000]\n [    26  17000]\n [    58  23000]\n [    30  62000]\n [    25  33000]\n [    59  29000]\n [    28  37000]\n [    39  77000]\n [    47 107000]\n [    52 138000]\n [    29  43000]\n [    27 137000]\n [    24  55000]\n [    40  72000]\n [    21  16000]\n [    57  26000]\n [    30 135000]\n [    48 119000]\n [    40  57000]\n [    35  75000]\n [    28  44000]\n [    37  74000]\n [    35  27000]\n [    37  79000]\n [    32 120000]\n [    29  75000]\n [    30  17000]\n [    25  79000]\n [    40 107000]\n [    24  19000]\n [    41  72000]\n [    38  61000]\n [    36 144000]\n [    42  64000]\n [    48  33000]\n [    48  30000]\n [    23  20000]\n [    55 130000]\n [    29 148000]\n [    42  65000]\n [    27  54000]\n [    37  55000]\n [    25  22000]\n [    59 143000]\n [    42  54000]\n [    27  17000]\n [    47  49000]\n [    28  59000]\n [    33  69000]\n [    31  68000]\n [    35  23000]\n [    35  22000]\n [    57  33000]\n [    30 107000]\n [    46  23000]\n [    41  60000]\n [    33  41000]\n [    33  60000]\n [    47  47000]\n [    28  55000]\n [    45  32000]\n [    35  75000]\n [    59  42000]\n [    47  50000]\n [    47  51000]\n [    35  79000]\n [    39  42000]\n [    40  78000]\n [    23  48000]\n [    39  75000]\n [    35  57000]\n [    55  39000]\n [    31  71000]\n [    28 123000]\n [    42  80000]\n [    40  59000]\n [    48  74000]\n [    21  88000]\n [    53  72000]\n [    27  58000]\n [    35  47000]\n [    28  89000]\n [    26  80000]\n [    32 117000]\n [    42  75000]\n [    33 149000]\n [    41  80000]\n [    31  58000]\n [    39 134000]\n [    27  20000]\n [    29  83000]\n [    19  70000]\n [    19  85000]\n [    29  61000]\n [    39 134000]\n [    31  76000]\n [    41  72000]\n [    26  80000]\n [    40  61000]\n [    35  25000]\n [    48  96000]\n [    42 149000]\n [    28  79000]\n [    51 134000]\n [    33  28000]\n [    42  54000]\n [    45  22000]\n [    37  57000]\n [    34 112000]\n [    35  39000]\n [    22  27000]\n [    35  72000]\n [    39  59000]\n [    20  74000]\n [    46  32000]\n [    26  43000]\n [    29  83000]\n [    55 125000]\n [    37 146000]\n [    45 131000]\n [    33  43000]\n [    41  45000]\n [    42  79000]\n [    37 137000]\n [    24  84000]\n [    32  18000]\n [    56 104000]\n [    49  39000]\n [    28  85000]\n [    53 143000]\n [    30  89000]\n [    57  60000]\n [    40  75000]\n [    41  79000]\n [    20  82000]\n [    22  55000]\n [    35  88000]\n [    54  70000]\n [    31  15000]\n [    50  36000]\n [    42  65000]\n [    34  43000]\n [    42 108000]\n [    54  26000]\n [    19  21000]\n [    36  50000]\n [    37  70000]\n [    36 126000]\n [    47  20000]\n [    30  79000]\n [    59  83000]\n [    29  80000]\n [    43 112000]\n [    38  80000]\n [    58 144000]\n [    36 125000]\n [    49  28000]\n [    18  52000]\n [    30  15000]\n [    59  88000]\n [    27  57000]\n [    38  71000]\n [    31  89000]\n [    47  34000]\n [    31  74000]\n [    37  72000]\n [    40  57000]\n [    59 130000]\n [    49  65000]\n [    48  90000]\n [    46  22000]\n [    54 104000]\n [    35  20000]\n [    49 141000]\n [    48  41000]\n [    35  55000]\n [    36  60000]\n [    32 150000]\n [    18  68000]\n [    24  55000]\n [    42  90000]\n [    38  59000]\n [    60 108000]\n [    22  63000]\n [    24  32000]\n [    46  59000]\n [    48 134000]\n [    41  72000]\n [    50  44000]\n [    38  71000]\n [    24  23000]\n [    35  61000]\n [    37  80000]\n [    24  27000]\n [    26  84000]\n [    34  25000]\n [    36  54000]\n [    21  68000]\n [    41  71000]\n [    60  42000]\n [    52  90000]\n [    20  23000]\n [    51  23000]\n [    46  79000]\n [    30  49000]]\n\n\n\nprint(X_test)\n\n[[    36  33000]\n [    39  61000]\n [    36 118000]\n [    39 122000]\n [    26 118000]\n [    38  65000]\n [    20  36000]\n [    49  89000]\n [    31  18000]\n [    48 141000]\n [    34  72000]\n [    39  73000]\n [    35  72000]\n [    48 131000]\n [    53  82000]\n [    56 133000]\n [    60  83000]\n [    27  58000]\n [    28  87000]\n [    60 102000]\n [    40  75000]\n [    50  88000]\n [    44 139000]\n [    47  43000]\n [    45  26000]\n [    26  15000]\n [    58  47000]\n [    49  74000]\n [    53  34000]\n [    52 114000]\n [    39  42000]\n [    19  76000]\n [    18  86000]\n [    57  74000]\n [    27  84000]\n [    30  80000]\n [    22  18000]\n [    32  86000]\n [    50  20000]\n [    19  25000]\n [    47 144000]\n [    58 101000]\n [    34 115000]\n [    23  66000]\n [    56  60000]\n [    31 118000]\n [    48  35000]\n [    47 113000]\n [    39  79000]\n [    52  38000]\n [    24  58000]\n [    37  53000]\n [    42  80000]\n [    46  28000]\n [    42  73000]\n [    37  62000]\n [    60  42000]\n [    36  52000]\n [    58  95000]\n [    43 129000]\n [    27  89000]\n [    23  82000]\n [    38 112000]\n [    35  50000]\n [    36  99000]\n [    37 144000]\n [    26  35000]\n [    42  70000]\n [    43 133000]\n [    38  50000]\n [    46  96000]\n [    35  44000]\n [    38 113000]\n [    39  71000]\n [    26  52000]\n [    54 108000]\n [    33  51000]\n [    26  16000]\n [    30  87000]\n [    35  60000]\n [    29  28000]\n [    45  22000]\n [    46 117000]\n [    32  18000]\n [    22  81000]\n [    25  87000]\n [    48  33000]\n [    35  58000]\n [    47  23000]\n [    26  32000]\n [    32 135000]\n [    60  34000]\n [    52  21000]\n [    38  55000]\n [    25  90000]\n [    58  38000]\n [    49  88000]\n [    37  78000]\n [    35  77000]\n [    34  43000]]\n\n\n\nprint(y_train)\n\n[0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1\n 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 1\n 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1\n 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0\n 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1\n 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1\n 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n 0 1 1 0]\n\n\n\nprint(y_test)\n\n[0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0\n 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0\n 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 0 0]"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#feature-scaling",
    "href": "machine-learning/logistic-regression.html#feature-scaling",
    "title": "8  Logistische Regression",
    "section": "8.6 Feature Scaling",
    "text": "8.6 Feature Scaling\nDas Feature Scaling ist für diese Anwendung nicht unbedingt notwendig, zum Üben kann es aber noch einmal durchgeführt werden. Dabei kommt wieder die Standardisierung zum Einsatz.\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n\nprint(X_train)\n\n[[-1.68062015e+00 -5.92416706e-01]\n [ 8.69241193e-01  5.63566526e-01]\n [-6.01832657e-01 -1.03702564e+00]\n [ 9.67312783e-01 -1.15558802e+00]\n [-2.09546297e-01 -5.62776110e-01]\n [ 1.82740063e-01  8.00691292e-01]\n [-4.05689477e-01  1.30458142e+00]\n [ 1.16345596e+00  5.04285335e-01]\n [ 7.71169603e-01  2.96801165e-01]\n [ 6.73098013e-01 -8.88822663e-01]\n [ 3.78883243e-01 -2.96010749e-01]\n [ 4.76954833e-01 -4.73854323e-01]\n [-2.09546297e-01  1.18957591e-01]\n [ 3.78883243e-01  8.93169951e-02]\n [-9.94119017e-01  8.00691292e-01]\n [-6.99904247e-01  1.39350321e+00]\n [ 3.78883243e-01 -5.03494919e-01]\n [ 3.78883243e-01 -5.03494919e-01]\n [-1.68062015e+00  3.85722952e-01]\n [ 8.69241193e-01 -8.29541472e-01]\n [-9.94119017e-01 -1.12594743e+00]\n [-2.09546297e-01  5.96763994e-02]\n [ 1.16345596e+00 -1.21486922e+00]\n [-2.09546297e-01  6.52488313e-01]\n [-1.34031173e-02  1.78238782e-01]\n [-5.03761067e-01  1.42314380e+00]\n [-1.11474707e-01  1.78238782e-01]\n [-1.68062015e+00  5.04285335e-01]\n [ 8.46684727e-02 -5.62776110e-01]\n [ 1.16345596e+00 -9.77744450e-01]\n [ 2.80811653e-01 -1.18167175e-01]\n [-1.34031173e-02  2.37519974e-01]\n [ 2.24224345e+00 -6.81338493e-01]\n [ 1.06538437e+00  2.04559631e+00]\n [ 2.80811653e-01  5.96763994e-02]\n [-1.11474707e-01 -1.77448366e-01]\n [-1.09219061e+00  3.56082356e-01]\n [-4.05689477e-01 -1.12594743e+00]\n [ 3.78883243e-01 -5.33135515e-01]\n [ 8.69241193e-01  1.48598186e-01]\n [-1.87676333e+00  3.85722952e-01]\n [-1.34031173e-02 -1.06666624e+00]\n [-2.09546297e-01 -4.73854323e-01]\n [-8.96047427e-01 -2.96010749e-01]\n [-1.34031173e-02  5.96763994e-02]\n [-1.87676333e+00 -7.40619685e-01]\n [ 8.46684727e-02 -2.36729558e-01]\n [-2.09546297e-01 -1.18167175e-01]\n [-6.01832657e-01 -8.85265792e-02]\n [ 9.67312783e-01 -1.30379100e+00]\n [ 4.76954833e-01  1.03781606e+00]\n [-1.77869174e+00 -1.48163458e+00]\n [-1.58254856e+00  8.93169951e-02]\n [-8.96047427e-01 -1.09630683e+00]\n [ 1.45767073e+00  2.40128346e+00]\n [ 1.55574232e+00  1.03781606e+00]\n [-1.19026220e+00  3.26441761e-01]\n [-1.09219061e+00  8.93169951e-02]\n [-1.09219061e+00 -1.60019696e+00]\n [ 2.80811653e-01  2.16415869e+00]\n [-2.09546297e-01 -9.18463259e-01]\n [ 1.94802868e+00  1.57134678e+00]\n [ 3.78883243e-01  5.33925931e-01]\n [-1.28833379e+00  5.93207122e-01]\n [-1.34031173e-02 -5.03494919e-01]\n [-2.09546297e-01  1.15637844e+00]\n [-5.03761067e-01  9.19253675e-01]\n [-2.09546297e-01  2.31236167e+00]\n [-1.77869174e+00 -1.27415041e+00]\n [ 8.69241193e-01  3.85722952e-01]\n [ 9.67312783e-01  1.06745665e+00]\n [ 7.71169603e-01 -7.10979089e-01]\n [ 8.46684727e-02 -5.33135515e-01]\n [-1.34031173e-02  7.11769505e-01]\n [-7.97975837e-01 -7.70260280e-01]\n [ 3.78883243e-01 -1.15558802e+00]\n [ 2.80811653e-01 -2.66370153e-01]\n [-9.94119017e-01  5.63566526e-01]\n [-9.94119017e-01  6.22847718e-01]\n [ 1.82740063e-01  5.96763994e-02]\n [-1.38640538e+00 -1.21486922e+00]\n [ 1.35959914e+00  2.28272108e+00]\n [-1.38640538e+00 -1.77448366e-01]\n [-1.34031173e-02  3.26441761e-01]\n [ 2.80811653e-01 -6.51697898e-01]\n [ 1.06538437e+00 -1.18522862e+00]\n [-2.09546297e-01 -2.96010749e-01]\n [-1.09219061e+00 -1.15558802e+00]\n [ 1.82740063e-01  1.09709725e+00]\n [-8.96047427e-01  4.45004144e-01]\n [ 2.14417186e+00  2.07879378e-01]\n [ 2.80811653e-01 -3.55291941e-01]\n [-2.09546297e-01  8.30331888e-01]\n [-1.09219061e+00  5.04285335e-01]\n [ 3.78883243e-01 -1.77448366e-01]\n [-7.97975837e-01 -6.51697898e-01]\n [-1.09219061e+00 -1.54091577e+00]\n [ 2.04610027e+00 -1.36307219e+00]\n [-6.99904247e-01 -2.07088962e-01]\n [-1.19026220e+00 -1.06666624e+00]\n [ 2.14417186e+00 -1.18522862e+00]\n [-8.96047427e-01 -9.48103855e-01]\n [ 1.82740063e-01  2.37519974e-01]\n [ 9.67312783e-01  1.12673784e+00]\n [ 1.45767073e+00  2.04559631e+00]\n [-7.97975837e-01 -7.70260280e-01]\n [-9.94119017e-01  2.01595572e+00]\n [-1.28833379e+00 -4.14573132e-01]\n [ 2.80811653e-01  8.93169951e-02]\n [-1.58254856e+00 -1.57055636e+00]\n [ 1.94802868e+00 -1.27415041e+00]\n [-6.99904247e-01  1.95667452e+00]\n [ 1.06538437e+00  1.48242499e+00]\n [ 2.80811653e-01 -3.55291941e-01]\n [-2.09546297e-01  1.78238782e-01]\n [-8.96047427e-01 -7.40619685e-01]\n [-1.34031173e-02  1.48598186e-01]\n [-2.09546297e-01 -1.24450981e+00]\n [-1.34031173e-02  2.96801165e-01]\n [-5.03761067e-01  1.51206559e+00]\n [-7.97975837e-01  1.78238782e-01]\n [-6.99904247e-01 -1.54091577e+00]\n [-1.19026220e+00  2.96801165e-01]\n [ 2.80811653e-01  1.12673784e+00]\n [-1.28833379e+00 -1.48163458e+00]\n [ 3.78883243e-01  8.93169951e-02]\n [ 8.46684727e-02 -2.36729558e-01]\n [-1.11474707e-01  2.22343989e+00]\n [ 4.76954833e-01 -1.47807771e-01]\n [ 1.06538437e+00 -1.06666624e+00]\n [ 1.06538437e+00 -1.15558802e+00]\n [-1.38640538e+00 -1.45199398e+00]\n [ 1.75188550e+00  1.80847155e+00]\n [-7.97975837e-01  2.34200227e+00]\n [ 4.76954833e-01 -1.18167175e-01]\n [-9.94119017e-01 -4.44213728e-01]\n [-1.34031173e-02 -4.14573132e-01]\n [-1.19026220e+00 -1.39271279e+00]\n [ 2.14417186e+00  2.19379929e+00]\n [ 4.76954833e-01 -4.44213728e-01]\n [-9.94119017e-01 -1.54091577e+00]\n [ 9.67312783e-01 -5.92416706e-01]\n [-8.96047427e-01 -2.96010749e-01]\n [-4.05689477e-01  3.95207943e-04]\n [-6.01832657e-01 -2.92453878e-02]\n [-2.09546297e-01 -1.36307219e+00]\n [-2.09546297e-01 -1.39271279e+00]\n [ 1.94802868e+00 -1.06666624e+00]\n [-6.99904247e-01  1.12673784e+00]\n [ 8.69241193e-01 -1.36307219e+00]\n [ 3.78883243e-01 -2.66370153e-01]\n [-4.05689477e-01 -8.29541472e-01]\n [-4.05689477e-01 -2.66370153e-01]\n [ 9.67312783e-01 -6.51697898e-01]\n [-8.96047427e-01 -4.14573132e-01]\n [ 7.71169603e-01 -1.09630683e+00]\n [-2.09546297e-01  1.78238782e-01]\n [ 2.14417186e+00 -7.99900876e-01]\n [ 9.67312783e-01 -5.62776110e-01]\n [ 9.67312783e-01 -5.33135515e-01]\n [-2.09546297e-01  2.96801165e-01]\n [ 1.82740063e-01 -7.99900876e-01]\n [ 2.80811653e-01  2.67160569e-01]\n [-1.38640538e+00 -6.22057302e-01]\n [ 1.82740063e-01  1.78238782e-01]\n [-2.09546297e-01 -3.55291941e-01]\n [ 1.75188550e+00 -8.88822663e-01]\n [-6.01832657e-01  5.96763994e-02]\n [-8.96047427e-01  1.60098738e+00]\n [ 4.76954833e-01  3.26441761e-01]\n [ 2.80811653e-01 -2.96010749e-01]\n [ 1.06538437e+00  1.48598186e-01]\n [-1.58254856e+00  5.63566526e-01]\n [ 1.55574232e+00  8.93169951e-02]\n [-9.94119017e-01 -3.25651345e-01]\n [-2.09546297e-01 -6.51697898e-01]\n [-8.96047427e-01  5.93207122e-01]\n [-1.09219061e+00  3.26441761e-01]\n [-5.03761067e-01  1.42314380e+00]\n [ 4.76954833e-01  1.78238782e-01]\n [-4.05689477e-01  2.37164286e+00]\n [ 3.78883243e-01  3.26441761e-01]\n [-6.01832657e-01 -3.25651345e-01]\n [ 1.82740063e-01  1.92703393e+00]\n [-9.94119017e-01 -1.45199398e+00]\n [-7.97975837e-01  4.15363548e-01]\n [-1.77869174e+00  3.00358036e-02]\n [-1.77869174e+00  4.74644739e-01]\n [-7.97975837e-01 -2.36729558e-01]\n [ 1.82740063e-01  1.92703393e+00]\n [-6.01832657e-01  2.07879378e-01]\n [ 3.78883243e-01  8.93169951e-02]\n [-1.09219061e+00  3.26441761e-01]\n [ 2.80811653e-01 -2.36729558e-01]\n [-2.09546297e-01 -1.30379100e+00]\n [ 1.06538437e+00  8.00691292e-01]\n [ 4.76954833e-01  2.37164286e+00]\n [-8.96047427e-01  2.96801165e-01]\n [ 1.35959914e+00  1.92703393e+00]\n [-4.05689477e-01 -1.21486922e+00]\n [ 4.76954833e-01 -4.44213728e-01]\n [ 7.71169603e-01 -1.39271279e+00]\n [-1.34031173e-02 -3.55291941e-01]\n [-3.07617887e-01  1.27494082e+00]\n [-2.09546297e-01 -8.88822663e-01]\n [-1.48447697e+00 -1.24450981e+00]\n [-2.09546297e-01  8.93169951e-02]\n [ 1.82740063e-01 -2.96010749e-01]\n [-1.68062015e+00  1.48598186e-01]\n [ 8.69241193e-01 -1.09630683e+00]\n [-1.09219061e+00 -7.70260280e-01]\n [-7.97975837e-01  4.15363548e-01]\n [ 1.75188550e+00  1.66026857e+00]\n [-1.34031173e-02  2.28272108e+00]\n [ 7.71169603e-01  1.83811214e+00]\n [-4.05689477e-01 -7.70260280e-01]\n [ 3.78883243e-01 -7.10979089e-01]\n [ 4.76954833e-01  2.96801165e-01]\n [-1.34031173e-02  2.01595572e+00]\n [-1.28833379e+00  4.45004144e-01]\n [-5.03761067e-01 -1.51127517e+00]\n [ 1.84995709e+00  1.03781606e+00]\n [ 1.16345596e+00 -8.88822663e-01]\n [-8.96047427e-01  4.74644739e-01]\n [ 1.55574232e+00  2.19379929e+00]\n [-6.99904247e-01  5.93207122e-01]\n [ 1.94802868e+00 -2.66370153e-01]\n [ 2.80811653e-01  1.78238782e-01]\n [ 3.78883243e-01  2.96801165e-01]\n [-1.68062015e+00  3.85722952e-01]\n [-1.48447697e+00 -4.14573132e-01]\n [-2.09546297e-01  5.63566526e-01]\n [ 1.65381391e+00  3.00358036e-02]\n [-6.01832657e-01 -1.60019696e+00]\n [ 1.26152755e+00 -9.77744450e-01]\n [ 4.76954833e-01 -1.18167175e-01]\n [-3.07617887e-01 -7.70260280e-01]\n [ 4.76954833e-01  1.15637844e+00]\n [ 1.65381391e+00 -1.27415041e+00]\n [-1.77869174e+00 -1.42235339e+00]\n [-1.11474707e-01 -5.62776110e-01]\n [-1.34031173e-02  3.00358036e-02]\n [-1.11474707e-01  1.68990916e+00]\n [ 9.67312783e-01 -1.45199398e+00]\n [-6.99904247e-01  2.96801165e-01]\n [ 2.14417186e+00  4.15363548e-01]\n [-7.97975837e-01  3.26441761e-01]\n [ 5.75026423e-01  1.27494082e+00]\n [ 8.46684727e-02  3.26441761e-01]\n [ 2.04610027e+00  2.22343989e+00]\n [-1.11474707e-01  1.66026857e+00]\n [ 1.16345596e+00 -1.21486922e+00]\n [-1.87676333e+00 -5.03494919e-01]\n [-6.99904247e-01 -1.60019696e+00]\n [ 2.14417186e+00  5.63566526e-01]\n [-9.94119017e-01 -3.55291941e-01]\n [ 8.46684727e-02  5.96763994e-02]\n [-6.01832657e-01  5.93207122e-01]\n [ 9.67312783e-01 -1.03702564e+00]\n [-6.01832657e-01  1.48598186e-01]\n [-1.34031173e-02  8.93169951e-02]\n [ 2.80811653e-01 -3.55291941e-01]\n [ 2.14417186e+00  1.80847155e+00]\n [ 1.16345596e+00 -1.18167175e-01]\n [ 1.06538437e+00  6.22847718e-01]\n [ 8.69241193e-01 -1.39271279e+00]\n [ 1.65381391e+00  1.03781606e+00]\n [-2.09546297e-01 -1.45199398e+00]\n [ 1.16345596e+00  2.13451810e+00]\n [ 1.06538437e+00 -8.29541472e-01]\n [-2.09546297e-01 -4.14573132e-01]\n [-1.11474707e-01 -2.66370153e-01]\n [-5.03761067e-01  2.40128346e+00]\n [-1.87676333e+00 -2.92453878e-02]\n [-1.28833379e+00 -4.14573132e-01]\n [ 4.76954833e-01  6.22847718e-01]\n [ 8.46684727e-02 -2.96010749e-01]\n [ 2.24224345e+00  1.15637844e+00]\n [-1.48447697e+00 -1.77448366e-01]\n [-1.28833379e+00 -1.09630683e+00]\n [ 8.69241193e-01 -2.96010749e-01]\n [ 1.06538437e+00  1.92703393e+00]\n [ 3.78883243e-01  8.93169951e-02]\n [ 1.26152755e+00 -7.40619685e-01]\n [ 8.46684727e-02  5.96763994e-02]\n [-1.28833379e+00 -1.36307219e+00]\n [-2.09546297e-01 -2.36729558e-01]\n [-1.34031173e-02  3.26441761e-01]\n [-1.28833379e+00 -1.24450981e+00]\n [-1.09219061e+00  4.45004144e-01]\n [-3.07617887e-01 -1.30379100e+00]\n [-1.11474707e-01 -4.44213728e-01]\n [-1.58254856e+00 -2.92453878e-02]\n [ 3.78883243e-01  5.96763994e-02]\n [ 2.24224345e+00 -7.99900876e-01]\n [ 1.45767073e+00  6.22847718e-01]\n [-1.68062015e+00 -1.36307219e+00]\n [ 1.35959914e+00 -1.36307219e+00]\n [ 8.69241193e-01  2.96801165e-01]\n [-6.99904247e-01 -5.92416706e-01]]\n\n\n\nprint(X_test)\n\n[[-0.11147471 -1.06666624]\n [ 0.18274006 -0.23672956]\n [-0.11147471  1.4527844 ]\n [ 0.18274006  1.57134678]\n [-1.09219061  1.4527844 ]\n [ 0.08466847 -0.11816717]\n [-1.68062015 -0.97774445]\n [ 1.16345596  0.59320712]\n [-0.60183266 -1.51127517]\n [ 1.06538437  2.1345181 ]\n [-0.30761789  0.089317  ]\n [ 0.18274006  0.11895759]\n [-0.2095463   0.089317  ]\n [ 1.06538437  1.83811214]\n [ 1.55574232  0.38572295]\n [ 1.84995709  1.89739333]\n [ 2.24224345  0.41536355]\n [-0.99411902 -0.32565134]\n [-0.89604743  0.53392593]\n [ 2.24224345  0.97853487]\n [ 0.28081165  0.17823878]\n [ 1.26152755  0.56356653]\n [ 0.67309801  2.07523691]\n [ 0.96731278 -0.77026028]\n [ 0.7711696  -1.27415041]\n [-1.09219061 -1.60019696]\n [ 2.04610027 -0.6516979 ]\n [ 1.16345596  0.14859819]\n [ 1.55574232 -1.03702564]\n [ 1.45767073  1.33422201]\n [ 0.18274006 -0.79990088]\n [-1.77869174  0.20787938]\n [-1.87676333  0.50428533]\n [ 1.94802868  0.14859819]\n [-0.99411902  0.44500414]\n [-0.69990425  0.32644176]\n [-1.48447697 -1.51127517]\n [-0.50376107  0.50428533]\n [ 1.26152755 -1.45199398]\n [-1.77869174 -1.303791  ]\n [ 0.96731278  2.22343989]\n [ 2.04610027  0.94889427]\n [-0.30761789  1.36386261]\n [-1.38640538 -0.08852658]\n [ 1.84995709 -0.26637015]\n [-0.60183266  1.4527844 ]\n [ 1.06538437 -1.00738505]\n [ 0.96731278  1.30458142]\n [ 0.18274006  0.29680117]\n [ 1.45767073 -0.91846326]\n [-1.28833379 -0.32565134]\n [-0.01340312 -0.47385432]\n [ 0.47695483  0.32644176]\n [ 0.86924119 -1.21486922]\n [ 0.47695483  0.11895759]\n [-0.01340312 -0.20708896]\n [ 2.24224345 -0.79990088]\n [-0.11147471 -0.50349492]\n [ 2.04610027  0.7710507 ]\n [ 0.57502642  1.77883095]\n [-0.99411902  0.59320712]\n [-1.38640538  0.38572295]\n [ 0.08466847  1.27494082]\n [-0.2095463  -0.56277611]\n [-0.11147471  0.88961308]\n [-0.01340312  2.22343989]\n [-1.09219061 -1.00738505]\n [ 0.47695483  0.0300358 ]\n [ 0.57502642  1.89739333]\n [ 0.08466847 -0.56277611]\n [ 0.86924119  0.80069129]\n [-0.2095463  -0.74061968]\n [ 0.08466847  1.30458142]\n [ 0.18274006  0.0596764 ]\n [-1.09219061 -0.50349492]\n [ 1.65381391  1.15637844]\n [-0.40568948 -0.53313551]\n [-1.09219061 -1.57055636]\n [-0.69990425  0.53392593]\n [-0.2095463  -0.26637015]\n [-0.79797584 -1.21486922]\n [ 0.7711696  -1.39271279]\n [ 0.86924119  1.4231438 ]\n [-0.50376107 -1.51127517]\n [-1.48447697  0.35608236]\n [-1.1902622   0.53392593]\n [ 1.06538437 -1.06666624]\n [-0.2095463  -0.32565134]\n [ 0.96731278 -1.36307219]\n [-1.09219061 -1.09630683]\n [-0.50376107  1.95667452]\n [ 2.24224345 -1.03702564]\n [ 1.45767073 -1.42235339]\n [ 0.08466847 -0.41457313]\n [-1.1902622   0.62284772]\n [ 2.04610027 -0.91846326]\n [ 1.16345596  0.56356653]\n [-0.01340312  0.26716057]\n [-0.2095463   0.23751997]\n [-0.30761789 -0.77026028]]"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#das-model-trainieren",
    "href": "machine-learning/logistic-regression.html#das-model-trainieren",
    "title": "8  Logistische Regression",
    "section": "8.7 Das Model trainieren",
    "text": "8.7 Das Model trainieren\n\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)\n\nLogisticRegression(random_state=0)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(random_state=0)"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#eine-vorhersage-machen",
    "href": "machine-learning/logistic-regression.html#eine-vorhersage-machen",
    "title": "8  Logistische Regression",
    "section": "8.8 Eine Vorhersage machen",
    "text": "8.8 Eine Vorhersage machen\nWichtig: Für die Vorhersage müssen die Daten an die neue Skala angepasst werden!\n\nclassifier.predict(sc.transform([[30,87000]]))\n\narray([0])"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#die-testergebnisse-vorhersagen",
    "href": "machine-learning/logistic-regression.html#die-testergebnisse-vorhersagen",
    "title": "8  Logistische Regression",
    "section": "8.9 Die Testergebnisse vorhersagen",
    "text": "8.9 Die Testergebnisse vorhersagen\n\ny_pred = classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_pred),1)), 1))\n\n[[0 0]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [1 0]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 1]\n [0 0]\n [1 1]\n [1 0]\n [1 1]\n [1 0]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [0 0]\n [0 1]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [0 1]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [0 1]\n [0 1]\n [0 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [1 0]\n [0 0]\n [0 1]\n [1 1]\n [0 0]\n [0 0]\n [1 0]\n [0 0]\n [1 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [0 0]\n [0 0]\n [0 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [0 1]\n [0 0]\n [0 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [0 1]\n [0 0]\n [0 0]]"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#confusion-matrix-ausgeben",
    "href": "machine-learning/logistic-regression.html#confusion-matrix-ausgeben",
    "title": "8  Logistische Regression",
    "section": "8.10 Confusion Matrix ausgeben",
    "text": "8.10 Confusion Matrix ausgeben\nDie Wikipedia erklärt sehr gut, wie eine Wahrheitsmatrix (confusion matrix) bei der Gütebewertung des Modells helfen kann.\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n# Die Rate der korrekten Vorhersagen\naccuracy_score(y_test, y_pred)\n\n[[52  6]\n [11 31]]\n\n\n0.83"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#visualisierung-des-trainingsets",
    "href": "machine-learning/logistic-regression.html#visualisierung-des-trainingsets",
    "title": "12  Logistische Regression",
    "section": "12.11 Visualisierung des Trainingsets",
    "text": "12.11 Visualisierung des Trainingsets"
  },
  {
    "objectID": "machine-learning/logistic-regression.html#visualisierung-des-testsets",
    "href": "machine-learning/logistic-regression.html#visualisierung-des-testsets",
    "title": "12  Logistische Regression",
    "section": "12.12 Visualisierung des Testsets",
    "text": "12.12 Visualisierung des Testsets"
  },
  {
    "objectID": "preparation/index.html",
    "href": "preparation/index.html",
    "title": "Fingerübungen",
    "section": "",
    "text": "Bevor es mit Machine Learning losgeht, empfehlen sich einige Fingerübungen mit zentralen Pythonbibliotheken."
  },
  {
    "objectID": "introduction/jupyter-usage.html#weiterführende-informationen",
    "href": "introduction/jupyter-usage.html#weiterführende-informationen",
    "title": "1  Einführung in JupyterLab",
    "section": "1.3 Weiterführende Informationen",
    "text": "1.3 Weiterführende Informationen\nEin gutes Video in deutscher Sprache zu JupyterLab gibt es meines Wissens noch nicht. Dafür aber einige zum Vorläufer der Software, Jupyter Notebook. Sie finden es auf YouTube unter https://www.youtube.com/watch?v=1S4Cgtkxqhs.\nViele weitere Videos sind in der offiziellen Dokumentation verlinkt. Probieren Sie auf YouTube die Echtzeitübersetzung aus, diese ist oft ganz passabel."
  },
  {
    "objectID": "introduction/jupyter-usage.html#jupyterlab-in-aktuellem-ordner-starten",
    "href": "introduction/jupyter-usage.html#jupyterlab-in-aktuellem-ordner-starten",
    "title": "1  Einführung in JupyterLab",
    "section": "1.2 JupyterLab in aktuellem Ordner starten",
    "text": "1.2 JupyterLab in aktuellem Ordner starten\nJupyterLab starten Sie in der Regel von der Kommandozeile aus (Ausnahme: Anaconda). Um gleich im richtigen Arbeitsverzeichnis zu landen, navigieren Sie zuerst in dieses. Dann können Sie folgendes Argument übergeben:\n$ jupyterlab --notebook_dir=.\nDabei steht . für das aktuelle Verzeichnis."
  },
  {
    "objectID": "preparation/numpy.html#einführung-in-numpy",
    "href": "preparation/numpy.html#einführung-in-numpy",
    "title": "2  numpy",
    "section": "2.1 Einführung in numpy",
    "text": "2.1 Einführung in numpy\nEs gibt viele gute Tutorials und Anleitungen für numpy im Netz. Empfehlenswert ist hierbei die Einheit in der w3schools. Das Übertragen der Beispiele in ein Jupyter Notebook hilft, die neue Entwicklungsumgebung besser kennenzulernen. Sie können natürlich auch direkt auf der Webseite der w3schools die Beispiele ausführen."
  },
  {
    "objectID": "preparation/numpy.html#einfache-statistische-funktionen-mit-numpy",
    "href": "preparation/numpy.html#einfache-statistische-funktionen-mit-numpy",
    "title": "2  numpy",
    "section": "2.2 Einfache statistische Funktionen mit numpy",
    "text": "2.2 Einfache statistische Funktionen mit numpy\nEbenfalls auf den Seiten der w3schools sind einige Beispiele zu grundlegenden statistischen Funktionen zu finden. Hierbei sind vor allem die folgenden wichtig für das Verständnis der kommenden Konzepte:\n\nMittelwert\nMedian\nStandardabweichung"
  },
  {
    "objectID": "preparation/pandas.html#einführung-in-pandas",
    "href": "preparation/pandas.html#einführung-in-pandas",
    "title": "4  pandas",
    "section": "4.1 Einführung in pandas",
    "text": "4.1 Einführung in pandas\nAuch zu pandas existieren zahlreiche Tutorials im Netz sowie Videos und Kurse. Sie können zum Warmwerden zunächst auch die Beispiele der w3schools durcharbeiten, da sie alles Notwendige für die folgenden Schritte enthalten."
  },
  {
    "objectID": "preparation/pandas.html#kompetenzcheck",
    "href": "preparation/pandas.html#kompetenzcheck",
    "title": "4  pandas",
    "section": "4.2 Kompetenzcheck",
    "text": "4.2 Kompetenzcheck\nAm Ende können Sie auch eine abschließende Übung machen, um Ihren Lernfortschritt zu überprüfen."
  },
  {
    "objectID": "machine-learning/multiple-linear-regression.html#eine-vorhersage-mit-neuen-daten-machen",
    "href": "machine-learning/multiple-linear-regression.html#eine-vorhersage-mit-neuen-daten-machen",
    "title": "7  Multiple lineare Regression",
    "section": "7.10 Eine Vorhersage mit neuen Daten machen",
    "text": "7.10 Eine Vorhersage mit neuen Daten machen\n\nregressor.predict([[0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2]])\n\narray([103015.2])"
  },
  {
    "objectID": "preparation/index.html#eng",
    "href": "preparation/index.html#eng",
    "title": "Fingerübungen",
    "section": "Eng",
    "text": "Eng"
  },
  {
    "objectID": "preparation/index.html#automatische-übersetzung-nutzen",
    "href": "preparation/index.html#automatische-übersetzung-nutzen",
    "title": "Fingerübungen",
    "section": "Automatische Übersetzung nutzen",
    "text": "Automatische Übersetzung nutzen\nDie einschlägigen Dokumentationen und API-Referenzen im Bereich Künstliche Intelligenz (KI) und Machine Learning sind in englischer Sprache geschrieben. Das schreckt viele ab, sich mit dem Thema genauer auseinanderzusetzen. Es gibt aber eine Möglichkeit, sich die Sache zu vereinfachen. Lassen Sie sich die Webseiten automatisch übersetzen.\n\n\n\nQuelle: Screenshot von https://translate.google.de\n\n\nPrüfen Sie auch die Übersetzungsmöglichkeiten von https://www.deepl.com/, um die beste Entscheidung für sich zu treffen."
  },
  {
    "objectID": "introduction/jupyter-usage.html#section",
    "href": "introduction/jupyter-usage.html#section",
    "title": "1  Einführung in JupyterLab",
    "section": "1.1 ",
    "text": "1.1"
  },
  {
    "objectID": "introduction/jupyter-usage.html#installation",
    "href": "introduction/jupyter-usage.html#installation",
    "title": "1  Einführung in JupyterLab",
    "section": "1.1 Installation",
    "text": "1.1 Installation\nEs gibt mindestens zwei verschiedene Möglichkeiten, JupyterLab zu installieren:\n\nim Rahmen der großen Data-Science-Distribution Anaconda, die für die gängigen Betriebssysteme frei verfügbar ist.\nals Python-Modul\n\nIm Rahmen dieses Kurses reicht Option 2 aus. Entsprechend kann der Dokumentation auf der Website des Projekts gefolgt werden.\nSollten Sie dennoch Anaconda verwenden wollen, ist conda statt pip das Installationstool für weitere Python-Pakete."
  },
  {
    "objectID": "preparation/numpy.html#video-zu-statistischen-grundlagen",
    "href": "preparation/numpy.html#video-zu-statistischen-grundlagen",
    "title": "2  numpy",
    "section": "2.3 Video zu statistischen Grundlagen",
    "text": "2.3 Video zu statistischen Grundlagen\nDie Wissenschaftlerin Mai Thi Nguyen-Kim hat auf YouTube ein Video veröffentlicht, in dem sie einige statistische Grundfunktionen erläutert."
  },
  {
    "objectID": "machine-learning/logistic-regression.html#wahrheitsmatrix-confusion-matrix-ausgeben",
    "href": "machine-learning/logistic-regression.html#wahrheitsmatrix-confusion-matrix-ausgeben",
    "title": "8  Logistische Regression",
    "section": "8.10 Wahrheitsmatrix (confusion matrix) ausgeben",
    "text": "8.10 Wahrheitsmatrix (confusion matrix) ausgeben\nDie Wikipedia erklärt sehr gut, wie eine Wahrheitsmatrix (confusion matrix) bei der Gütebewertung des Modells helfen kann.\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n# Die Rate der korrekten Vorhersagen\naccuracy_score(y_test, y_pred)\n\n[[52  6]\n [11 31]]\n\n\n0.83"
  },
  {
    "objectID": "machine-learning/index.html#eine-kurze-geschichte-der-künstlichen-intelligenz-ki",
    "href": "machine-learning/index.html#eine-kurze-geschichte-der-künstlichen-intelligenz-ki",
    "title": "Machine Learning",
    "section": "Eine kurze Geschichte der Künstlichen Intelligenz (KI)",
    "text": "Eine kurze Geschichte der Künstlichen Intelligenz (KI)\nZu empfehlen ist der Themenband “Künstliche Intelligenz” von Wittpahl (2019). Darin führen Kirste und Schürholz (2019) ein in die Entwicklung verschiedener Richtungen von KI und gehen auch auf das Machine Learning ein.\n\n\n\nQuelle: Crissy Jarvis on Unsplash\n\n\n\n\n\n\nKirste, Moritz, und Markus Schürholz. 2019. „Einleitung: Entwicklungswege zur KI“. In Künstliche Intelligenz, herausgegeben von Volker Wittpahl, 21–35. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-58042-4_1.\n\n\nWittpahl, Volker, Hrsg. 2019. Künstliche Intelligenz. Technologien  Anwendung  Gesellschaft. Berlin, Heidelberg: Springer Vieweg. https://link.springer.com/book/10.1007/978-3-662-58042-4."
  },
  {
    "objectID": "appendices/offene-fragen.html",
    "href": "appendices/offene-fragen.html",
    "title": "Appendix A — Antworten auf Fragen",
    "section": "",
    "text": "import numpy as np\n\n\narr = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n\nprint(arr[1, 1:4])\n\n[7 8 9]\n\n\nHole von beiden Elementen [0:2] jeweils das dritte Element [2].\n\narr = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n\nprint(arr[0:2, 2])\n\n[3 8]\n\n\nHole von beiden Elementen [0:2] jeweils die Elemente 2, 3 und 4 [1:4].\n\narr = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n\nprint(arr[0:2, 1:4])\n\n[[2 3 4]\n [7 8 9]]"
  },
  {
    "objectID": "appendices/offene-fragen.html#grafiken-in-matplotlib-vergrößern",
    "href": "appendices/offene-fragen.html#grafiken-in-matplotlib-vergrößern",
    "title": "Appendix A — Antworten auf Fragen",
    "section": "A.2 Grafiken in matplotlib vergrößern",
    "text": "A.2 Grafiken in matplotlib vergrößern\n\nimport matplotlib.pyplot as plt\n\n# Inches für Breite und Höhe\nplt.rcParams['figure.figsize'] = [12, 8]\n# Auflösung\nplt.rcParams['figure.dpi'] = 220 # 200 e.g. is really fine, but slower\n\nplt.plot([0, 2, 3, 4])\nplt.ylabel('some numbers')\nplt.xlabel('some other numbers')\nplt.show()"
  },
  {
    "objectID": "appendices/offene-fragen.html#interaktive-visualisierungen",
    "href": "appendices/offene-fragen.html#interaktive-visualisierungen",
    "title": "Appendix A — Antworten auf Fragen",
    "section": "A.3 Interaktive Visualisierungen",
    "text": "A.3 Interaktive Visualisierungen\nWie hier für die Version 3.0 von JupyterLab beschrieben, muss zunächst mit pip das Paket ipympl installiert werden. Danach ist es am besten, nicht nur den Kernel neu zu starten, sondern JupyterLab einmal zu stoppen, neu zu starten und den Browser ebenfalls zu aktualisieren.\n\n#%pip install ipympl\n%matplotlib inline\n%matplotlib widget\n\nimport matplotlib.pyplot as plt\n\n\nplt.plot([1,2,3,4,5,6,7], [10, 50, 100, 23,15,28,45], linewidth = 3, c = 'g')"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html",
    "href": "machine-learning/kaufabsicht.html",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "",
    "text": "Der folgende Code vervollständigt das Beispiel aus dem Abschnitt Daten vorbereiten, in dem die Kaufabsicht von Klient*innen vorhergesagt werden soll."
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#bibliotheken-installieren",
    "href": "machine-learning/kaufabsicht.html#bibliotheken-installieren",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.1 Bibliotheken installieren",
    "text": "9.1 Bibliotheken installieren\nFühren Sie die folgende Zelle aus, um zu überprüfen, dass alle notwendigen Bibliotheken installiert sind.\n\n#%pip install sklearn\n#%pip install numpy\n#%pip install pandas\n#%pip install matplotlib"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#bibliotheken-importieren",
    "href": "machine-learning/kaufabsicht.html#bibliotheken-importieren",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.2 Bibliotheken importieren",
    "text": "9.2 Bibliotheken importieren\nDie folgenden Bibliotheken brauchen Sie für die meisten Aufgaben. Ihr Import steht daher meistens am Anfang Ihrer Programme oder Notebooks.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#daten-importieren",
    "href": "machine-learning/kaufabsicht.html#daten-importieren",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.3 Daten importieren",
    "text": "9.3 Daten importieren\nDie Daten, die in diesem Beispiel als CSV-Datei vorliegen, wird mithilfe von pandas importiert.\n\ndf = pd.read_csv(\"data/dataset.csv\")\n\nDas geladene Datenset kann hier im Notebook angezeigt werden.\n\ndf\n\n\n\n\n\n  \n    \n      \n      Land\n      Alter\n      Gehalt\n      gekauft\n    \n  \n  \n    \n      0\n      Frankreich\n      44.0\n      72000.0\n      Nein\n    \n    \n      1\n      Griechenland\n      27.0\n      48000.0\n      Ja\n    \n    \n      2\n      Deutschland\n      30.0\n      54000.0\n      Nein\n    \n    \n      3\n      Griechenland\n      38.0\n      61000.0\n      Nein\n    \n    \n      4\n      Deutschland\n      40.0\n      NaN\n      Ja\n    \n    \n      5\n      Frankreich\n      35.0\n      58000.0\n      Ja\n    \n    \n      6\n      Griechenland\n      NaN\n      52000.0\n      Nein\n    \n    \n      7\n      Frankreich\n      48.0\n      79000.0\n      Ja\n    \n    \n      8\n      Deutschland\n      50.0\n      83000.0\n      Nein\n    \n    \n      9\n      Frankreich\n      37.0\n      67000.0\n      Ja"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#featurematrix-auswählen",
    "href": "machine-learning/kaufabsicht.html#featurematrix-auswählen",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.4 Featurematrix auswählen",
    "text": "9.4 Featurematrix auswählen\nZunächst werden die Features in einer Variable zusammengefasst, die einer Matrix entspricht.\n\nX = df.iloc[:, :-1].values\n\n\ny = df.iloc[:, -1].values\n\n\nprint(X)\n\n[['Frankreich' 44.0 72000.0]\n ['Griechenland' 27.0 48000.0]\n ['Deutschland' 30.0 54000.0]\n ['Griechenland' 38.0 61000.0]\n ['Deutschland' 40.0 nan]\n ['Frankreich' 35.0 58000.0]\n ['Griechenland' nan 52000.0]\n ['Frankreich' 48.0 79000.0]\n ['Deutschland' 50.0 83000.0]\n ['Frankreich' 37.0 67000.0]]\n\n\n\nprint(y)\n\n['Nein' 'Ja' 'Nein' 'Nein' 'Ja' 'Ja' 'Nein' 'Ja' 'Nein' 'Ja']"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#fehlende-daten-berücksichtigen",
    "href": "machine-learning/kaufabsicht.html#fehlende-daten-berücksichtigen",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.5 Fehlende Daten berücksichtigen",
    "text": "9.5 Fehlende Daten berücksichtigen\nWenn wenige Daten fehlen, können diese Datensätze in der Regel ignoriert bzw. entfernt werden. Fehlen in vielen Datensätzen Daten, gibt es verschiedene Strategien, diese zu ersetzen. Eine davon ist, den Mittelwert aus den vorhandenen Daten zu bilden. Hierfür stellt scikit-learn ein Verfahren zur Verfügung.\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X[:, 1:3])\nX[:, 1:3] = imputer.transform(X[:, 1:3])\n\n\nprint(X)\n\n[['Frankreich' 44.0 72000.0]\n ['Griechenland' 27.0 48000.0]\n ['Deutschland' 30.0 54000.0]\n ['Griechenland' 38.0 61000.0]\n ['Deutschland' 40.0 63777.77777777778]\n ['Frankreich' 35.0 58000.0]\n ['Griechenland' 38.77777777777778 52000.0]\n ['Frankreich' 48.0 79000.0]\n ['Deutschland' 50.0 83000.0]\n ['Frankreich' 37.0 67000.0]]\n\n\n\n\n\n\n\n\nAufgabe\n\n\n\nRecherchieren Sie verwendeten Klassen und Methoden in der Dokumentation von scikit-learn."
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#kategorien-in-den-daten-kodieren",
    "href": "machine-learning/kaufabsicht.html#kategorien-in-den-daten-kodieren",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.6 Kategorien in den Daten kodieren",
    "text": "9.6 Kategorien in den Daten kodieren\nDamit der Algorithmus die Daten schnell und eindeutig verarbeiten kann, müssen Textwerte als Zahlenwerte kodiert werden, hier also die Länder. Ein gängiges Verfahren ist hierbei, binäre Vektoren aus den möglichen Kombinationen der Kategorien zu erstellen. Bei diesem Vorgehen werden neue Spalten angelegt, die diese Vektoren abbilden. Lesen Sie hierzu auch den Artikel über One Hot Encoding, wie dieses Verfahren genannt wird.\nDa im vorliegenden Datenset sowohl in den unabhängigen als auch in der abhängigen Variable kategorische Daten vorliegen, ist der Vorgang zweimal notwendig.\n\n9.6.1 Die unabhängige Variable kodieren\nAuch hierfür werden wieder Methoden von scikit-learn verwendet.\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n\n\nprint(ct)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('encoder', OneHotEncoder(), [0])])\n\n\n\nprint(X)\n\n[[0.0 1.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [1.0 0.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [1.0 0.0 0.0 40.0 63777.77777777778]\n [0.0 1.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [0.0 1.0 0.0 48.0 79000.0]\n [1.0 0.0 0.0 50.0 83000.0]\n [0.0 1.0 0.0 37.0 67000.0]]\n\n\n\n\n9.6.2 Die abhängige Variable kodieren\nDa die Werte der abhängigen Variablen binär abgebildet werden können, ist hier One-Hot-Encoding nicht notwendig.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\n\n\nprint(y)\n\n[1 0 1 1 0 0 1 0 1 0]"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#daten-aufteilen-in-training--und-testset",
    "href": "machine-learning/kaufabsicht.html#daten-aufteilen-in-training--und-testset",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.7 Daten aufteilen in Training- und Testset",
    "text": "9.7 Daten aufteilen in Training- und Testset\nFür den eigentlichen Prozess des “Maschinenlernens” wird das Datenset in ein Trainingsset und ein Testset aufgeteilt.\nMit dem Trainingsset wird das Machine-Learning-Modell trainiert, mit dem Testset wird die Vorhersagegüte des Modells getestet. Hierbei wird so getan, als ob es sich bei den Testdaten um zukünftige reale Daten handelt.\nscikit-learn stellt auch hierfür ein Verfahren bereit.\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n\n\nprint(X_train)\n\n[[0.0 1.0 0.0 37.0 67000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [0.0 1.0 0.0 48.0 79000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 1.0 0.0 44.0 72000.0]\n [0.0 1.0 0.0 35.0 58000.0]]\n\n\n\nprint(X_test)\n\n[[1.0 0.0 0.0 30.0 54000.0]\n [1.0 0.0 0.0 50.0 83000.0]\n [1.0 0.0 0.0 40.0 63777.77777777778]]\n\n\n\nprint(y_train)\n\n[0 0 1 0 1 1 0]\n\n\n\nprint(y_test)\n\n[1 1 0]"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#feature-scaling",
    "href": "machine-learning/kaufabsicht.html#feature-scaling",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.8 Feature Scaling",
    "text": "9.8 Feature Scaling\nFeature Scaling ist die Anpassung der unabhängigen Daten in einer Weise, dass sie alle im gleichen Verhältnis zueinander stehen. Dadurch wird vermieden, dass ein Feature andere Features dominiert.\nWichtig: Feature Scaling wird immer erst nach der Aufteilung des Datensets durchgeführt! Damit wird Informationsverlust bei den Testdaten vermieden.\n\nX_test[:, 3:]\n\narray([[30.0, 54000.0],\n       [50.0, 83000.0],\n       [40.0, 63777.77777777778]], dtype=object)\n\n\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = sc.transform(X_test[:, 3:])\n\n\nprint(X_train)\n\n[[0.0 1.0 0.0 -0.2029809015697542 0.44897082661305115]\n [0.0 0.0 1.0 -1.821689357126023 -1.4170641714974423]\n [0.0 0.0 1.0 0.08478949052913817 -1.0242146982110225]\n [0.0 1.0 0.0 1.5775983995421416 1.62751924647231]\n [0.0 0.0 1.0 -0.041110056014127316 -0.14030338331657835]\n [0.0 1.0 0.0 0.930115017319634 0.9400326682210757]\n [0.0 1.0 0.0 -0.526722592681008 -0.4349404882813931]]\n\n\n\nprint(X_test)\n\n[[1.0 0.0 0.0 -1.3360768204591424 -0.8277899615678128]\n [1.0 0.0 0.0 1.9013400906533953 2.02036871975873]\n [1.0 0.0 0.0 0.28263163509712647 0.13250875091010228]]"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#trainieren-des-modells",
    "href": "machine-learning/kaufabsicht.html#trainieren-des-modells",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.9 Trainieren des Modells",
    "text": "9.9 Trainieren des Modells\n\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)\n\nLogisticRegression(random_state=0)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(random_state=0)"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#eine-vorhersage-mit-neuen-daten-machen",
    "href": "machine-learning/kaufabsicht.html#eine-vorhersage-mit-neuen-daten-machen",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.10 Eine Vorhersage mit neuen Daten machen",
    "text": "9.10 Eine Vorhersage mit neuen Daten machen\nEinen neuen Datensatz erstellen:\n\nnew_data = [0.0, 0.0, 1.0, 39, 160000]\n\nDen Datensatz zum richtigen Typ wandeln und in die richtige Form bringen:\n\nnew_data = np.array(new_data).reshape(1, -1)\nnew_data\n\narray([[0.0e+00, 0.0e+00, 1.0e+00, 3.9e+01, 1.6e+05]])\n\n\nDas Segment ausgeben, das skaliert werden soll:\n\nnew_data[:, 3:]\n\narray([[3.9e+01, 1.6e+05]])\n\n\nDie Transformation auf das Segment anwenden und zurückschreiben:\n\nnew_data[:, 3:] = sc.transform(new_data[:, 3:])\nnew_data\n\narray([[0.  , 0.  , 1.  , 0.12, 9.58]])\n\n\nDie Vorhersage machen:\n\nclassifier.predict(new_data)\n\narray([0])"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#die-testdaten-vorhersagen",
    "href": "machine-learning/kaufabsicht.html#die-testdaten-vorhersagen",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.11 Die Testdaten vorhersagen",
    "text": "9.11 Die Testdaten vorhersagen\nWeil es jetzt mehrere Features gibt, ist das Zeichnen eine mehrdimensionalen Graphen nicht möglich. Daher werden im Folgenden die Profite aus den Trainingsdaten mit denen aus dem Testset verglichen. Hierbei kann die Güte des Modells erneut an der Abweichung der vorhergesagten zu den Testwerten gemessen werden.\n\nX_test\n\narray([[1.0, 0.0, 0.0, -1.3360768204591424, -0.8277899615678128],\n       [1.0, 0.0, 0.0, 1.9013400906533953, 2.02036871975873],\n       [1.0, 0.0, 0.0, 0.28263163509712647, 0.13250875091010228]],\n      dtype=object)\n\n\n\ny_pred = classifier.predict(X_test)\ny_pred\n\narray([0, 1, 0])\n\n\nUm die vorhergesagten und bekannten Daten nebeneinanderstellen zu können, wird das numpy-Array umgeformt:\n\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)), 1))\n\n[[0 1]\n [1 1]\n [0 0]]"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#confusion-matrix-ausgeben",
    "href": "machine-learning/kaufabsicht.html#confusion-matrix-ausgeben",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.12 Confusion Matrix ausgeben",
    "text": "9.12 Confusion Matrix ausgeben\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n# Die Rate der korrekten Vorhersagen\naccuracy_score(y_test, y_pred)\n\n[[1 0]\n [2 0]]\n\n\n0.3333333333333333"
  },
  {
    "objectID": "machine-learning/kaufabsicht.html#wahrheitsmatrix-confusion-matrix-ausgeben",
    "href": "machine-learning/kaufabsicht.html#wahrheitsmatrix-confusion-matrix-ausgeben",
    "title": "9  Kaufabsicht vorhersagen",
    "section": "9.12 Wahrheitsmatrix (confusion matrix) ausgeben",
    "text": "9.12 Wahrheitsmatrix (confusion matrix) ausgeben\nDie Wikipedia erklärt sehr gut, wie eine Wahrheitsmatrix (confusion matrix) bei der Gütebewertung des Modells helfen kann.\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Die Wahrheitsmatrix sieht aus wie folgt:\")\nprint(cm)\n# Die Rate der korrekten Vorhersagen\nprint(\"Der Accuracy Score beträgt {} %.\".format(accuracy_score(y_test, y_pred)*100))\n\nDie Wahrheitsmatrix sieht aus wie folgt:\n[[1 0]\n [1 1]]\nDer Accuracy Score beträgt 66.66666666666666 %."
  },
  {
    "objectID": "appendices/hedgedoc.html",
    "href": "appendices/hedgedoc.html",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "",
    "text": "Im Folgenden sind die Links aus dem kollaborativen Pad zur Veranstaltung aufgelistet."
  },
  {
    "objectID": "appendices/hedgedoc.html#der-zweite-workshoptag-findet-online-statt",
    "href": "appendices/hedgedoc.html#der-zweite-workshoptag-findet-online-statt",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.1 Der zweite Workshoptag findet online statt",
    "text": "B.1 Der zweite Workshoptag findet online statt\n\nTeamsraum am Freitag, 14.10.2022"
  },
  {
    "objectID": "appendices/hedgedoc.html#erwartungen-an-den-workshop",
    "href": "appendices/hedgedoc.html#erwartungen-an-den-workshop",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.2 Erwartungen an den Workshop",
    "text": "B.2 Erwartungen an den Workshop\n\nAm Ende der Veranstaltung möchte ich …\n… das Thema für meinen Unterricht aufbereiten können\nIdeen für KI im Unterricht und deren Umsetzung\nGute Ansätze für die Vermittlung des Machine Lerning Themas für den Unterricht haben.\nTools für KI im Unterricht\nEinen Einstieg für meinen Unterricht mit Python gefunden haben.\nEinführung in Python, neue Facetten im Bereich Maschinelles Lernen\nUnterrichtsideen\nEinstieg in Python\nneue Ideen für Unterrichtsinhalte\nEinsatzmöglichkeiten für JupterLab kennen lernen (Abgrenzung JupyterHub)\nEinen guten Überblick über Jupyter-Notebook, pandas, numpy, … bekommen und deren Anwendung."
  },
  {
    "objectID": "appendices/hedgedoc.html#linktracker",
    "href": "appendices/hedgedoc.html#linktracker",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.3 Linktracker",
    "text": "B.3 Linktracker\nIn der folgenden Liste können wir Quellen notieren, die wir mit anderen tauschen wollen.\n\nB.3.1 Donnerstag, 13.10.2022\n\nMatheformeln mit LaTeX\nStatistik-Exkurs mit Mai\n\n\nB.3.1.1 (Web)tools\n\nEmpfehlung für Bildschirm-Zoom und Kommentierung: Sysinternals-> ZoomIt (Microsoft aber frei verfügbar) -> ZoomIt\nhttps://openai.com/ Hier sind die beiden großen KIs “GPT-3” und “DALL-E 2” zum Ausprobieren. Man hat ein gewisses kostenloses Kontingent zur Verfügung, danach muss gezahlt werden.\nml5.js, Ausprobieren am Ende der Seite. Aufbauend auf p5.js ist ml5.js eine Bibliothekssammlung für ML-Anwendungen im Browser.\nRStudio Professionelle Umgebung zur Datenanalyse\nKI-Übersetzer deepL\n\n\n\nB.3.1.2 Python\n\nPython Flask Baukastensystem für Webserver-Anwendungen; Alternative ist Bottle, das nur mit einer Datei auskommt und Ähnliches kann wie Flask.\nSpotipy Python-Package für den Zugriff auf die Spotify-API\n\n\n\nB.3.1.3 JupyterLab\n\nJupyterLab Benutzeroberfläche erklärt\nJupyterLab mit Docker nutzen\n\n\n\nB.3.1.4 JupyterHub\n\nBlogbeitrag meines Kollegen Marvin Kastner zu Erfahrungen mit JupyterHub in Prüfungen\nInstallationshinweise für einen eigenen JupyterHub (sehr TUHH-bezogen)\n\n\n\nB.3.1.5 Matplotlib\n\nEinführungstutorial\n\nimport matplotlib.pyplot as plt\nplt.plot([0, 2, 3, 4])\nplt.ylabel('some numbers')\nplt.show()\n\n\nB.3.1.6 Pandas\n\nEinführungstutorial\n\n\n\n\nB.3.2 Freitag, 14.10.2022\n\nKaggle Daten und Code für Data Science. Auch Challenges von Data Scientists werden hier ausgetragen. Ein Beispiel, an dem ich beteiligt war: Hack dich schlau! Die lange Nacht der Strompreisprognosen\n\n\n\nDatenmaterial zum Download\n\n\n\n“Künstliche Intelligenz (Open Access)”\nhttps://www.heise.de/hintergrund/Wie-sich-Kuenstler-gegen-die-Nutzung-ihrer-Bilder-als-KI-Vorlagen-wehren-7306494.html\nhttps://openfuture.eu/publication/ai_commons-white-paper/\nhttps://plotly.com/\nhttps://anvil.works/\nhttps://talkpython.fm/\n\nimport matplotlib.pyplot as plt\n\n# Inches für Breite und Höhe\nplt.rcParams['figure.figsize'] = [12, 8]\n# Auflösung\nplt.rcParams['figure.dpi'] = 120 # 200 e.g. is really fine, but slower\n\nplt.plot([0, 2, 3, 4])\nplt.ylabel('some numbers')\nplt.xlabel('some other numbers')\nplt.show()\n\nhttps://forms.technologyreview.com/in-machines-we-trust/\nhttps://www.kaggle.com/c/hackathontuhh\nhttps://scikit-learn.org/stable/\nhttps://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer\nExplainable AI\n\nBespiel: Gehalt aus Berufserfahrung vorhersagen\nTrainingsset\nplt.scatter(X_train, y_train, color = 'red')\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Gehalt vs. Erfahrung (Trainingset)')\nplt.xlabel('Berufserfahrung in Jahren')\nplt.ylabel('Gehalt')\nplt.show()\nTestset\nplt.scatter(X_test, y_test, color = 'red')\n# Hier muss nichts ersetzt werden!\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Gehalt vs. Erfahrung (Testset)')\nplt.xlabel('Berufserfahrung in Jahren')\nplt.ylabel('Gehalt')\nplt.show()"
  },
  {
    "objectID": "appendices/hedgedoc.html#kontakt",
    "href": "appendices/hedgedoc.html#kontakt",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.9 Kontakt",
    "text": "B.9 Kontakt\n\nAxel Dürkop\nme@axel-duerkop.de\nhttps://axel-duerkop.de/"
  },
  {
    "objectID": "appendices/hedgedoc.html#allgemeines",
    "href": "appendices/hedgedoc.html#allgemeines",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.1 Allgemeines",
    "text": "B.1 Allgemeines\n\nMatheformeln mit LaTeX\nStatistik-Exkurs mit Mai\nNeue KIs werfen rechtliche Fragen auf\nWhitepaper: Wie müssen offene Lizenzen an das KI-Zeitalter angepasst werden?"
  },
  {
    "objectID": "appendices/hedgedoc.html#webtools",
    "href": "appendices/hedgedoc.html#webtools",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.2 (Web)tools",
    "text": "B.2 (Web)tools\n\nEmpfehlung für Bildschirm-Zoom und Kommentierung: Sysinternals-> ZoomIt (Microsoft aber frei verfügbar) -> ZoomIt\nhttps://openai.com/ Hier sind die beiden großen KIs “GPT-3” und “DALL-E 2” zum Ausprobieren. Man hat ein gewisses kostenloses Kontingent zur Verfügung, danach muss gezahlt werden.\nml5.js, Ausprobieren am Ende der Seite. Aufbauend auf p5.js ist ml5.js eine Bibliothekssammlung für ML-Anwendungen im Browser.\nRStudio Professionelle Umgebung zur Datenanalyse\nKI-Übersetzer deepL\nKaggle Daten und Code für Data Science. Auch Challenges von Data Scientists werden hier ausgetragen. Ein Beispiel, an dem ich beteiligt war: Hack dich schlau! Die lange Nacht der Strompreisprognosen\nPlotly zur interaktiven Visualisierung\nAnvil: HTML und CSS mit Python schreiben"
  },
  {
    "objectID": "appendices/hedgedoc.html#python",
    "href": "appendices/hedgedoc.html#python",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.4 Python",
    "text": "B.4 Python\n\nPython Flask Baukastensystem für Webserver-Anwendungen; Alternative ist Bottle, das nur mit einer Datei auskommt und Ähnliches kann wie Flask.\nSpotipy Python-Package für den Zugriff auf die Spotify-API"
  },
  {
    "objectID": "appendices/hedgedoc.html#jupyterlab",
    "href": "appendices/hedgedoc.html#jupyterlab",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.5 JupyterLab",
    "text": "B.5 JupyterLab\n\nJupyterLab Benutzeroberfläche erklärt\nJupyterLab mit Docker nutzen"
  },
  {
    "objectID": "appendices/hedgedoc.html#jupyterhub",
    "href": "appendices/hedgedoc.html#jupyterhub",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.6 JupyterHub",
    "text": "B.6 JupyterHub\n\nBlogbeitrag meines Kollegen Marvin Kastner zu Erfahrungen mit JupyterHub in Prüfungen\nInstallationshinweise für einen eigenen JupyterHub (sehr TUHH-bezogen)"
  },
  {
    "objectID": "appendices/hedgedoc.html#matplotlib",
    "href": "appendices/hedgedoc.html#matplotlib",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.7 Matplotlib",
    "text": "B.7 Matplotlib\n\nEinführungstutorial"
  },
  {
    "objectID": "appendices/hedgedoc.html#pandas",
    "href": "appendices/hedgedoc.html#pandas",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.8 Pandas",
    "text": "B.8 Pandas\n\nEinführungstutorial"
  },
  {
    "objectID": "appendices/hedgedoc.html#podcasts",
    "href": "appendices/hedgedoc.html#podcasts",
    "title": "Appendix B — Kollaboratives Pad",
    "section": "B.3 Podcasts",
    "text": "B.3 Podcasts\n\nIn Machines We Trust\nDer Python-Podcast"
  }
]